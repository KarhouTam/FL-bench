{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengsl/code/FL-bench/test_similar/test_utils.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weight = torch.load(weight_path)\n"
     ]
    }
   ],
   "source": [
    "from test_utils import *\n",
    "tag = f\"c0\"\n",
    "weight_dict = load_weight_dict_by_tag('../out/FedTest5-resnet18/2024-10-19-11:47:36/grad_lists', tag)\n",
    "# cal_similay_by_tag('weight_lists/202405281805-avg-ss/',\"server\", unselect_keys=['bn', 'num_batches_tracked','downsample'], describe='202405281805-avg-ss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = LayerFilter(unselect_keys=['num_batches_tracked','running_mean','running_var'], all_select_keys=['layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'base.layer1.0.conv1.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.0.bn1.weight' : torch.Size([64]),\n",
      "'base.layer1.0.bn1.bias' : torch.Size([64]),\n",
      "'base.layer1.0.conv2.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.0.bn2.weight' : torch.Size([64]),\n",
      "'base.layer1.0.bn2.bias' : torch.Size([64]),\n",
      "'base.layer1.1.conv1.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.1.bn1.weight' : torch.Size([64]),\n",
      "'base.layer1.1.bn1.bias' : torch.Size([64]),\n",
      "'base.layer1.1.conv2.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.1.bn2.weight' : torch.Size([64]),\n",
      "'base.layer1.1.bn2.bias' : torch.Size([64]),\n",
      "'base.layer2.0.conv1.weight' : torch.Size([128, 64, 3, 3]),\n",
      "'base.layer2.0.bn1.weight' : torch.Size([128]),\n",
      "'base.layer2.0.bn1.bias' : torch.Size([128]),\n",
      "'base.layer2.0.conv2.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.0.bn2.weight' : torch.Size([128]),\n",
      "'base.layer2.0.bn2.bias' : torch.Size([128]),\n",
      "'base.layer2.0.downsample.0.weight' : torch.Size([128, 64, 1, 1]),\n",
      "'base.layer2.0.downsample.1.weight' : torch.Size([128]),\n",
      "'base.layer2.0.downsample.1.bias' : torch.Size([128]),\n",
      "'base.layer2.1.conv1.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.1.bn1.weight' : torch.Size([128]),\n",
      "'base.layer2.1.bn1.bias' : torch.Size([128]),\n",
      "'base.layer2.1.conv2.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.1.bn2.weight' : torch.Size([128]),\n",
      "'base.layer2.1.bn2.bias' : torch.Size([128]),\n",
      "'base.layer3.0.conv1.weight' : torch.Size([256, 128, 3, 3]),\n",
      "'base.layer3.0.bn1.weight' : torch.Size([256]),\n",
      "'base.layer3.0.bn1.bias' : torch.Size([256]),\n",
      "'base.layer3.0.conv2.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.0.bn2.weight' : torch.Size([256]),\n",
      "'base.layer3.0.bn2.bias' : torch.Size([256]),\n",
      "'base.layer3.0.downsample.0.weight' : torch.Size([256, 128, 1, 1]),\n",
      "'base.layer3.0.downsample.1.weight' : torch.Size([256]),\n",
      "'base.layer3.0.downsample.1.bias' : torch.Size([256]),\n",
      "'base.layer3.1.conv1.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.1.bn1.weight' : torch.Size([256]),\n",
      "'base.layer3.1.bn1.bias' : torch.Size([256]),\n",
      "'base.layer3.1.conv2.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.1.bn2.weight' : torch.Size([256]),\n",
      "'base.layer3.1.bn2.bias' : torch.Size([256]),\n",
      "'base.layer4.0.conv1.weight' : torch.Size([512, 256, 3, 3]),\n",
      "'base.layer4.0.bn1.weight' : torch.Size([512]),\n",
      "'base.layer4.0.bn1.bias' : torch.Size([512]),\n",
      "'base.layer4.0.conv2.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.0.bn2.weight' : torch.Size([512]),\n",
      "'base.layer4.0.bn2.bias' : torch.Size([512]),\n",
      "'base.layer4.0.downsample.0.weight' : torch.Size([512, 256, 1, 1]),\n",
      "'base.layer4.0.downsample.1.weight' : torch.Size([512]),\n",
      "'base.layer4.0.downsample.1.bias' : torch.Size([512]),\n",
      "'base.layer4.1.conv1.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.1.bn1.weight' : torch.Size([512]),\n",
      "'base.layer4.1.bn1.bias' : torch.Size([512]),\n",
      "'base.layer4.1.conv2.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.1.bn2.weight' : torch.Size([512]),\n",
      "'base.layer4.1.bn2.bias' : torch.Size([512]),\n"
     ]
    }
   ],
   "source": [
    "for i in filter(weight_dict[0][0]).keys():\n",
    "    print(f\"'{i}' : {weight_dict[0][0][i].shape},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.layer1.0.conv1.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.0.bn1.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.bn1.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.conv2.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.0.bn2.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.bn2.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.conv1.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.1.bn1.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.bn1.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.conv2.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.1.bn2.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.bn2.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer2.0.conv1.weight          |  294912 bytes | 0.66% | shape: torch.Size([128, 64, 3, 3])\n",
      "base.layer2.0.bn1.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.bn1.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.conv2.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.0.bn2.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.bn2.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.downsample.0.weight   |   32768 bytes | 0.07% | shape: torch.Size([128, 64, 1, 1])\n",
      "base.layer2.0.downsample.1.weight   |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.downsample.1.bias     |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.conv1.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.1.bn1.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.bn1.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.conv2.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.1.bn2.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.bn2.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer3.0.conv1.weight          | 1179648 bytes | 2.64% | shape: torch.Size([256, 128, 3, 3])\n",
      "base.layer3.0.bn1.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.bn1.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.conv2.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.0.bn2.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.bn2.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.downsample.0.weight   |  131072 bytes | 0.29% | shape: torch.Size([256, 128, 1, 1])\n",
      "base.layer3.0.downsample.1.weight   |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.downsample.1.bias     |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.conv1.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.1.bn1.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.bn1.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.conv2.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.1.bn2.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.bn2.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer4.0.conv1.weight          | 4718592 bytes | 10.56% | shape: torch.Size([512, 256, 3, 3])\n",
      "base.layer4.0.bn1.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.bn1.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.conv2.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.0.bn2.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.bn2.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.downsample.0.weight   |  524288 bytes | 1.17% | shape: torch.Size([512, 256, 1, 1])\n",
      "base.layer4.0.downsample.1.weight   |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.downsample.1.bias     |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.conv1.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.1.bn1.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.bn1.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.conv2.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.1.bn2.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.bn2.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "weight_0 = filter(weight_dict[0][0])\n",
    "total_size = calculate_data_size(weight_0)\n",
    "for i in weight_0.keys():\n",
    "    size = cal_memory(weight_0[i])\n",
    "    ratio = size / total_size\n",
    "    print(f\"{i:35} | {size:7} bytes | {ratio * 100:.2f}% | shape: {weight_0[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def cal_size(M, K, D, L):\n",
    "    if isinstance(M, list):\n",
    "        M = reduce(lambda x, y: x * y, M)\n",
    "    w1 = K * M / L \n",
    "    w2 = D * L\n",
    "    w = w1 + w2\n",
    "    r =  w / M\n",
    "    print(f\"M {M}, size: {w}, ratio: {r}, w1: {w1}, w2: {w2}\")\n",
    "cal_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_K_D_L(M, K=None, D=None, L=None):\n",
    "    # vector = vector.flatten()\n",
    "    # M = vector.shape[0]\n",
    "    if K is None and D is not None and L is not None:\n",
    "        max = L // 2\n",
    "        K = D * L * L // M\n",
    "        if K > max:\n",
    "            raise ValueError(f\"Not good. K is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is None and L is not None:\n",
    "        if L // K <= 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        max = M // (4 * K)\n",
    "        D = K * M // (L * L)\n",
    "        if D > max:\n",
    "            raise ValueError(f\"Not good. D is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        min = 2 * K\n",
    "        L = int(math.sqrt(M * K // D))\n",
    "        if L < min:\n",
    "            raise ValueError(f\"Not good. L is too small, min is {min}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is not None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        if L // K < 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        r = K / L + D * L / M\n",
    "    else:\n",
    "        raise ValueError(f\"K, D, L must have one None\")\n",
    "    \n",
    "    if K < D:\n",
    "        raise ValueError(f\"Not good. K < D, now is {K} < {D}\")\n",
    "    return K, D, L, 1 - r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=32, D=32, L=768, r=0.9479166666666666\n"
     ]
    }
   ],
   "source": [
    "K, max_D, L, r = cal_K_D_L(512*512*3*3,K=32, D=32, L=256*3)\n",
    "print(f\"K={K}, D={max_D}, L={L}, r={r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "4-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "6-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "8-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "10-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "12-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "14-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "16-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "18-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "20-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n"
     ]
    }
   ],
   "source": [
    "# 遍历K和D，找到最好的K和D，使得r最大\n",
    "max_r = 0\n",
    "max_K = 0\n",
    "max_D = 0\n",
    "max_L = 0\n",
    "for K in [2,4,6,8,10,12,14,16,18,20]:\n",
    "    for max_D in range(1, K):\n",
    "        for L in range(2*K, 1024):\n",
    "            try:\n",
    "                K, max_D, L, r = cal_K_D_L(4096, K=K, D=max_D, L=L)\n",
    "                if L < 1024 and r > max_r:\n",
    "                    max_r = r\n",
    "                    max_K = K\n",
    "                    max_D = max_D\n",
    "                    max_L = L\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "    print(f\"{K}-th max_K={max_K}, max_D={max_D}, max_L={max_L}, max_r={max_r}\")\n",
    "print(f\"max_K={max_K}, max_D={max_D}, max_L={max_L}, max_r={max_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Dict\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from src.utils.my_utils import cal_memory\n",
    "\n",
    "\n",
    "class Compressor:\n",
    "    # 基类，用于压缩和解压缩\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def compress(self, tensor:torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    def uncompress(self, tensor:torch.Tensor):\n",
    "        pass\n",
    "    \n",
    "    def update_basis(self, update_dict:Dict[int, torch.Tensor]):\n",
    "        pass\n",
    "\n",
    "    def update_basis_by_vector(self, vector:torch.Tensor):\n",
    "        pass\n",
    "\n",
    "class TopkCompressor(Compressor):\n",
    "    '''\n",
    "    TopkCompressor类, 用于基于top-k百分比的有损压缩。\n",
    "    在压缩时，仅保留绝对值最大的K%个元素，并将结果转换为指定的稀疏矩阵格式；\n",
    "    在解压缩时，将稀疏矩阵转换回密集矩阵。\n",
    "    '''\n",
    "\n",
    "    def __init__(self, k_percent: float, sparse_format: str = 'csr', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.k_percent = k_percent  # 要保留的最大元素的百分比 (0 < k_percent <= 100)\n",
    "        if sparse_format.lower() not in ['coo', 'csr']:\n",
    "            raise ValueError(\"sparse_format must be one of 'coo' or 'csr'\")\n",
    "        self.sparse_format = sparse_format.lower()\n",
    "\n",
    "    def compress(self, tensor: torch.Tensor) -> Tuple[Union[torch.Tensor, torch.sparse.Tensor], torch.Tensor]:\n",
    "        '''\n",
    "        Args:\n",
    "            tensor: torch.Tensor, 待压缩的张量\n",
    "        Returns:\n",
    "            compressed_tensor: torch.sparse.Tensor, 压缩后的稀疏张量\n",
    "            error: torch.Tensor, 误差张量\n",
    "        '''\n",
    "        # 获取张量的形状和元素总数\n",
    "        original_shape = tensor.shape\n",
    "        num_elements = tensor.numel()\n",
    "        \n",
    "        # 计算要保留的元素数量（基于百分比）\n",
    "        k = int(num_elements * (self.k_percent / 100.0))\n",
    "        \n",
    "        # 将tensor展平，以便找到全局的k个最大值\n",
    "        flat_tensor = tensor.flatten()\n",
    "        abs_tensor = torch.abs(flat_tensor)\n",
    "\n",
    "        _, indices = torch.topk(abs_tensor, k)\n",
    "        compressed_tensor = torch.zeros_like(flat_tensor)\n",
    "        compressed_tensor[indices] = flat_tensor[indices]\n",
    "        compressed_tensor = compressed_tensor.unsqueeze(0)\n",
    "\n",
    "        # 将压缩后的张量转换为稀疏张量\n",
    "        if self.sparse_format == 'coo':\n",
    "            compressed_sparse_tensor = compressed_tensor.to_sparse_coo()\n",
    "        elif self.sparse_format == 'csr':\n",
    "            compressed_sparse_tensor = compressed_tensor.to_sparse_csr()\n",
    "        # 计算误差\n",
    "        error = tensor - compressed_tensor.reshape(original_shape)\n",
    "        return compressed_sparse_tensor, error\n",
    "\n",
    "    def uncompress(self, sparse_tensor: torch.sparse.Tensor, shape: Tuple[int, ...] = None) -> torch.Tensor:\n",
    "        '''\n",
    "        Args:\n",
    "            sparse_tensor: torch.sparse.Tensor, 压缩后的稀疏张量\n",
    "            shape: tuple, 原始张量的形状（如果需要的话）\n",
    "        Returns:\n",
    "            torch.Tensor, 解压后的密集张量\n",
    "        '''\n",
    "        # 将稀疏张量转换回密集张量\n",
    "        if sparse_tensor.layout == torch.sparse_coo or sparse_tensor.layout == torch.sparse_csr:\n",
    "            dense_tensor = sparse_tensor.to_dense()\n",
    "            dense_tensor = dense_tensor.squeeze(0)\n",
    "        \n",
    "        # 如果提供了形状，重新塑形\n",
    "        if shape is not None:\n",
    "            dense_tensor = dense_tensor.reshape(shape)\n",
    "        \n",
    "        return dense_tensor\n",
    "\n",
    "    def update_basis(self, update_dict: dict):\n",
    "        # 对于top-k压缩，无需更新基\n",
    "        pass\n",
    "\n",
    "    def update_basis_by_vector(self, vector: torch.Tensor):\n",
    "        # 对于top-k压缩，无需通过向量更新基\n",
    "        return {}\n",
    "\n",
    "class SVDCompressor(Compressor):\n",
    "    '''\n",
    "    SVDCompress类, 用于SVD压缩和解压缩, 用于SVDFed算法\n",
    "    '''\n",
    "    def __init__(self, L, R, use_scale=True, **kwargs):\n",
    "        self.U:torch.Tensor = None\n",
    "        self.L = L # 调整alpha\n",
    "        self.R = R # 误差阈值\n",
    "        self.use_scale = use_scale\n",
    "\n",
    "\n",
    "    def update_basis(self, update_dict:Dict[int, torch.Tensor]):\n",
    "        max_index = max(update_dict.keys())\n",
    "        key = next(iter(update_dict))\n",
    "        L = update_dict.get(key).shape[0]\n",
    "        self.U = torch.zeros(L, max_index+1)\n",
    "                    \n",
    "        # key是更新位置，value是更新的值\n",
    "        for k, v in update_dict.items():\n",
    "            self.U[:,k] = v.clone().detach()\n",
    "\n",
    "    def get_svd_error(self, vector_t, U):\n",
    "        # 依次计算grads中每个梯度的误差\n",
    "        total_error = 0\n",
    "        for i in range(vector_t.shape[1]):\n",
    "            g = vector_t[:,i].squeeze()\n",
    "            alpha = U.T @ g\n",
    "            # tmp = U @ alpha\n",
    "            # alpha = min(g.norm() / tmp.norm(), self.L) * alpha\n",
    "            g_approx = U @ alpha\n",
    "            error = g - g_approx\n",
    "            total_error += error.norm()/g.norm()\n",
    "        return total_error/vector_t.shape[1]\n",
    "    \n",
    "    def update_basis_by_vector(self, vector:torch.Tensor):\n",
    "        '''\n",
    "        Return update_dict\n",
    "        '''\n",
    "        update_dict = {}\n",
    "        vector_t = vector.T\n",
    "        U, S, _ = torch.linalg.svd(vector_t, full_matrices=False)\n",
    "\n",
    "        k = 0\n",
    "        l = 0\n",
    "        r = len(S)\n",
    "        while l < r:\n",
    "            mid = (l + r) // 2\n",
    "            t = self.get_svd_error(vector_t, U[:,:mid])\n",
    "            if t < self.R:\n",
    "                r = mid\n",
    "            else:\n",
    "                l = mid + 1\n",
    "        k = l\n",
    "\n",
    "        self.U = U[:,:k]\n",
    "        print(f\"Layer basis selected maximun: {k}, error: {t}, threshold: {self.R}\")\n",
    "        # update_dict 为全部U向量\n",
    "        for i in range(k):\n",
    "            update_dict[i] = self.U[:,i]\n",
    "        return update_dict\n",
    "    \n",
    "    def compress(self, vector:torch.Tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            vector: torch.Tensor, 压缩的张量\n",
    "        Returns:\n",
    "            a: torch.Tensor, 张量在基下的投影\n",
    "            e: torch.Tensor, 压缩张量的误差\n",
    "        '''\n",
    "        vector_t = vector.flatten().unsqueeze(0).T\n",
    "        if self.U is None:\n",
    "            return vector, torch.zeros_like(vector)\n",
    "        alpha = self.U.T @ vector_t\n",
    "        _g = self.U @ alpha\n",
    "\n",
    "        if self.use_scale:\n",
    "            scale = min((torch.std(vector_t)  + 1e-8)/ (torch.std(_g)  + 1e-8), self.L)\n",
    "        else:\n",
    "            scale = 1\n",
    "\n",
    "        alpha = scale*alpha\n",
    "        e = vector_t - scale*_g\n",
    "        return alpha, e.T.reshape(vector.shape)\n",
    "    \n",
    "    def uncompress(self, alpha:torch.Tensor, shape = None):\n",
    "        '''\n",
    "        Args:\n",
    "            alpha: torch.Tensor, 压缩后的alpha\n",
    "            shape: tuple, 原始张量的shape\n",
    "        Returns:\n",
    "            torch.Tensor, 解压后的张量\n",
    "        '''\n",
    "        # 如果a的维度刚好等于shape，直接返回\n",
    "        if alpha.shape == shape:\n",
    "            return alpha.clone().detach()\n",
    "        elif shape is None:\n",
    "            return (self.U @ alpha).T\n",
    "        else:\n",
    "            return (self.U @ alpha).T.reshape(shape)\n",
    "\n",
    "\n",
    "class QuickSlideSVDCompressor(Compressor):\n",
    "    def __init__(self, K, max_D, L, u_dtype='float32',**kwargs):\n",
    "        self.K = K # U的列数\n",
    "        self.max_D = max_D # 主动更新的维度\n",
    "        self.L = L # 参数切片的长度\n",
    "        self.U = None # 基础的U\n",
    "\n",
    "        self.cur_D = max_D\n",
    "        if u_dtype == 'float128':\n",
    "            self.dtype = np.float128\n",
    "        elif u_dtype == 'float64':\n",
    "            self.dtype = np.float64\n",
    "        elif u_dtype== 'float32':\n",
    "            self.dtype = np.float32\n",
    "        elif u_dtype == 'float16':\n",
    "            self.dtype = np.float16\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dtype {u_dtype}\")\n",
    "        # self.dtype = np.float16\n",
    "\n",
    "    def update_basis(self, update_dict: dict):\n",
    "        if self.U is None:\n",
    "            assert len(update_dict) == self.K, f\"First update_dict length must be {self.K}\"\n",
    "            max_index = max(update_dict.keys())\n",
    "            self.U = np.zeros((self.L, max_index + 1), dtype=self.dtype)  # Initialize U as numpy array\n",
    "        \n",
    "        # Key is the update index, value is the update value\n",
    "        for k, v in update_dict.items():\n",
    "            self.U[:, k] = v.copy()\n",
    "\n",
    "    def update_basis_by_vector(self, vector:torch.Tensor, update_threshold:float=0):\n",
    "        '''\n",
    "        Return update_dict\n",
    "        '''\n",
    "        # 通过向量更新U\n",
    "        flatten_L = vector.numel()\n",
    "        if flatten_L % self.L != 0:\n",
    "            return {}\n",
    "        vector = vector.reshape(-1, self.L)\n",
    "        if self.K > vector.shape[0]:\n",
    "            raise ValueError(f\"K {self.K} must less than vector.shape[0] {vector.shape[0]}\")\n",
    "        update_dict = {}\n",
    "        vector_t = vector.T.cpu().numpy()\n",
    "        if self.U is None:\n",
    "            # Compute U using SVD decomposition\n",
    "            U, S, V = svds(vector_t, k=self.K)\n",
    "            self.U = U.copy().astype(self.dtype)\n",
    "            # All U vectors are updated\n",
    "            for i in range(self.K):\n",
    "                update_dict[i] = self.U[:, i].copy()\n",
    "        \n",
    "        elif self.cur_D > 0:\n",
    "            # Reconstruct vector using U\n",
    "            e = vector_t - self.U @ self.U.T @ vector_t\n",
    "            U_e, S_e, V_e = svds(e, k=self.cur_D)\n",
    "            U_K_e = np.hstack([self.U, U_e], dtype=self.dtype)  # Concatenate the new basis vectors\n",
    "\n",
    "            alpha = U_K_e.T @ vector_t\n",
    "            \n",
    "            contribution = np.sum(alpha ** 2, axis=1)  # Calculate the contribution of each orthogonal vector\n",
    "            min_indices = np.argsort(contribution)[:self.cur_D]  # Get the D smallest contributing indices\n",
    "\n",
    "            min_indices_set = set(min_indices.tolist())\n",
    "            wait_D_update_set = set(range(self.K, self.K + self.cur_D))\n",
    "            sub_index = min_indices_set - wait_D_update_set\n",
    "            add_index = wait_D_update_set - min_indices_set\n",
    "\n",
    "            # \n",
    "            # Swap columns\n",
    "            U_K_e[:, list(sub_index)] = U_K_e[:, list(add_index)]\n",
    "            alpha[list(sub_index)] = alpha[list(add_index)]\n",
    "            U_K = U_K_e[:, :self.K]\n",
    "            if update_threshold > 0:\n",
    "                alpha_2 = alpha[:self.K]\n",
    "                e_2 = vector_t - U_K @ alpha_2\n",
    "                # Check if error difference is below the threshold, and skip update if so\n",
    "                if (np.linalg.norm(e) - np.linalg.norm(e_2)) / np.linalg.norm(e) < update_threshold:\n",
    "                    return {}\n",
    "            \n",
    "            self.U = U_K.copy()\n",
    "            # Return updated columns in dictionary form\n",
    "            for i in sub_index:\n",
    "                update_dict[i] = U_K_e[:, i].copy()\n",
    "            \n",
    "            # 动态调整更新的维度\n",
    "            actual_D = len(sub_index)   # 实际更新的维度\n",
    "            if actual_D >= self.cur_D//2:\n",
    "                self.cur_D = min(self.max_D, self.cur_D * 2)\n",
    "            \n",
    "            elif self.cur_D//4 < actual_D < self.cur_D//2:\n",
    "                self.cur_D = max(2, self.cur_D * 3 // 4)\n",
    "            else:\n",
    "                self.cur_D = max(2, self.cur_D // 2)\n",
    "            print(f\"actual_D/cur_D: {actual_D}/{self.cur_D}\")\n",
    "        return update_dict\n",
    "    \n",
    "    def compress(self, vector:torch.Tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            vector: torch.Tensor, 压缩的张量, 若vector的最后一个维度不能被L整除, 则返回自身, 否则返回压缩后的张量\n",
    "        Returns:\n",
    "            a: torch.Tensor, 张量在基下的投影\n",
    "            e: torch.Tensor, 压缩张量的误差\n",
    "        '''\n",
    "        flatten_L = vector.numel()\n",
    "        if flatten_L % self.L != 0:\n",
    "            print(f\"vector.numel() {flatten_L} can't divide L {self.L}. Return itself\")\n",
    "            return vector, torch.zeros_like(vector)\n",
    "   \n",
    "        vector_t = vector.reshape(-1, self.L).T\n",
    "        # 通过U重构vector\n",
    "        U = torch.from_numpy(self.U).to(vector.device, dtype=vector.dtype)\n",
    "        alpha = U.T @ vector_t\n",
    "        g = U @ alpha\n",
    "        e = vector_t - g\n",
    "        return alpha, e.T.reshape(vector.shape)\n",
    "\n",
    "    def uncompress(self, alpha:torch.Tensor, shape = None):\n",
    "        # 如果a的维度刚好等于shape，直接返回\n",
    "        if alpha.shape == shape:\n",
    "            return alpha.clone().detach()\n",
    "        elif shape is None:\n",
    "            U = torch.from_numpy(self.U).to(alpha.device, dtype=alpha.dtype)\n",
    "            return (U @ alpha).T\n",
    "        else:\n",
    "            U = torch.from_numpy(self.U).to(alpha.device, dtype=alpha.dtype)\n",
    "            return (U @ alpha).T.reshape(shape)\n",
    "\n",
    "\n",
    "class SlideSVDCompressor(Compressor):\n",
    "    def __init__(self, K, D, L, device='cpu'):\n",
    "        self.K = K # U的列数\n",
    "        self.D = D # 主动更新的维度\n",
    "        self.L = L # 参数切片的长度\n",
    "        self.U = None # 基础的U\n",
    "        self.device = device\n",
    "\n",
    "    def update_basis(self, update_dict:Dict[int, torch.Tensor]):\n",
    "        if self.U is None:\n",
    "            assert len(update_dict) == self.K, f\"First update_dict length must be {self.K}\"\n",
    "            max_index = max(update_dict.keys())\n",
    "            self.U = torch.zeros(self.L, max_index+1, device=self.device)\n",
    "        \n",
    "        # key是更新位置，value是更新的值\n",
    "        for k, v in update_dict.items():\n",
    "            self.U[:,k] = v.clone().detach().to(self.device)\n",
    "\n",
    "    def update_basis_by_vector(self, vector:torch.Tensor, update_threshold:float=0):\n",
    "        '''\n",
    "        Return update_dict\n",
    "        '''\n",
    "        # 通过向量更新U\n",
    "        flatten_L = vector.numel() if len(vector.shape) == 1 else (vector.numel() // vector.shape[0])\n",
    "        if flatten_L % self.L != 0:\n",
    "            return {}\n",
    "        vector = vector.reshape(-1, self.L)\n",
    "        if self.K > vector.shape[0]:\n",
    "            raise ValueError(f\"K {self.K} must less than vector.shape[0] {vector.shape[0]}\")\n",
    "        update_dict = {}\n",
    "        vector_t = vector.T\n",
    "        if self.U is None:\n",
    "            # 通过SVD分解得到U\n",
    "            U, S, V = torch.linalg.svd(vector_t, full_matrices=False)\n",
    "            self.U = U[:,:self.K].to(self.device)\n",
    "            # update_dict 为全部U向量\n",
    "            for i in range(self.K):\n",
    "                update_dict[i] = self.U[:,i]\n",
    "        \n",
    "        elif self.D > 0:\n",
    "            # 通过U重构vector\n",
    "            e = vector_t - self.U @ self.U.T @ vector_t\n",
    "            U_e, S_e, V_e = torch.linalg.svd(e, full_matrices=False)\n",
    "            U_K_e = torch.cat([self.U, U_e[:,:self.D]], dim=1)\n",
    "\n",
    "            alpha = U_K_e.T @ vector_t\n",
    "            \n",
    "            contribution = torch.sum(alpha ** 2, dim=1)  # 计算每个正交向量的贡献度（平方和）\n",
    "            _, min_indices = torch.topk(contribution, k=self.D, largest=False)\n",
    "\n",
    "            min_indices_set = set(min_indices.tolist())\n",
    "            wait_D_update_set = set([i for i in range(self.K, self.K+self.D)])\n",
    "            sub_index = min_indices_set - wait_D_update_set\n",
    "            add_index = wait_D_update_set - min_indices_set\n",
    "\n",
    "            # 交换列\n",
    "            U_K_e[:,list(sub_index)] = U_K_e[:,list(add_index)]\n",
    "            alpha[list(sub_index)] = alpha[list(add_index)]\n",
    "            U_K = U_K_e[:,:self.K]\n",
    "            alpha_2 = alpha[:self.K]\n",
    "            # alpha_2 = U_K.T @ vector_t\n",
    "            # alpha_2不需要重新计算，通过alpha和U_K_e的更新列计算\n",
    "            e_2 = vector_t - U_K @ alpha_2\n",
    "\n",
    "            # 若更新后的误差变化小于阈值，则不更新\n",
    "            # print(f\"de {(e.norm() - e_2.norm())/e.norm()}, update_threshold {update_threshold}\")\n",
    "            if (e.norm() - e_2.norm())/e.norm() < update_threshold:\n",
    "                return {}\n",
    "            \n",
    "            self.U = U_K_e[:,:self.K]\n",
    "            # 返回更新列字典\n",
    "            for i in sub_index:\n",
    "                update_dict[i] = U_K_e[:,i].clone().detach()\n",
    "        \n",
    "        return update_dict\n",
    "\n",
    "    def compress(self, vector:torch.Tensor):\n",
    "        '''\n",
    "        Args:\n",
    "            vector: torch.Tensor, 压缩的张量, 若vector的最后一个维度不能被L整除, 则返回自身, 否则返回压缩后的张量\n",
    "        Returns:\n",
    "            a: torch.Tensor, 张量在基下的投影\n",
    "            e: torch.Tensor, 压缩张量的误差\n",
    "        '''\n",
    "        flatten_L = vector.numel() if len(vector.shape) == 1 else (vector.numel() // vector.shape[0])\n",
    "        if flatten_L % self.L != 0:\n",
    "            print(f\"vector.numel() // vector.shape[0] {flatten_L} can't divide L {self.L}. Return itself\")\n",
    "            return vector, torch.zeros_like(vector)\n",
    "   \n",
    "        vector_t = vector.reshape(-1, self.L).T\n",
    "        # 通过U重构vector\n",
    "        alpha = self.U.T @ vector_t\n",
    "        g = self.U @ alpha\n",
    "        e = vector_t - g\n",
    "        return alpha, e.T.reshape(vector.shape)\n",
    "\n",
    "    def uncompress(self, alpha:torch.Tensor, shape = None):\n",
    "        # 如果a的维度刚好等于shape，直接返回\n",
    "        if alpha.shape == shape:\n",
    "            return alpha.clone().detach()\n",
    "        elif shape is None:\n",
    "            return (self.U @ alpha).T\n",
    "        else:\n",
    "            return (self.U @ alpha).T.reshape(shape)\n",
    "\n",
    "class CompressorCombin:\n",
    "    def __init__(self, setting_dict:Dict[str, tuple], class_name='SlideSVDCompressor', device='cpu', **kwargs):\n",
    "        '''\n",
    "        CompressorCombin类, 用于组合多个Compress类, 为多层参数提供压缩和解压缩功能\n",
    "        Args:\n",
    "            setting_dict: key是参数名, value是元组(K, D, L), K是U的列数, D是主动更新的维度, L是参数切片的长度\n",
    "        '''\n",
    "        if not isinstance(setting_dict, dict):\n",
    "            raise ValueError(\"setting_dict must be a dict\")\n",
    "        \n",
    "        compressor = globals()[class_name]\n",
    "\n",
    "        self.setting_dict = setting_dict\n",
    "        self.compressor_dict:Dict[str, Compressor] = {}\n",
    "        for key, value in setting_dict.items():\n",
    "            if isinstance(value, list):\n",
    "                value = tuple(value)\n",
    "            self.compressor_dict[key] = compressor(*value, **kwargs, device=device)\n",
    "        self.device = device\n",
    "\n",
    "    def update_basis_by_vector(self, model_params:Dict[str, Tensor]):\n",
    "        '''\n",
    "        通过model_params更新全部compressor的基\n",
    "        Args:\n",
    "            model_params: 模型参数字典\n",
    "        Returns:\n",
    "            dict: 更新字典\n",
    "        '''\n",
    "        res = {}\n",
    "        for key, value in model_params.items():\n",
    "            if key not in self.compressor_dict:\n",
    "                continue\n",
    "            compressor = self.compressor_dict[key]\n",
    "            res[key] = compressor.update_basis_by_vector(value)\n",
    "        return res\n",
    "\n",
    "    def compress(self, model_params:Dict[str, Tensor], can_update_basis_func=None, **kwargs) -> Tuple[Dict[str, Tensor], dict, Dict[str, Tensor]]:\n",
    "        '''\n",
    "        压缩combine中全部compressor的参数\n",
    "        Args:\n",
    "            model_params: 模型参数字典, 如果key不在compressor_dict中, 则不压缩\n",
    "            can_update_basis_func: 是否可以更新基函数的函数, 返回True或False\n",
    "        Returns:\n",
    "            combin_alpha: 压缩后的alpha字典 \n",
    "            combin_update_dict: 更新字典\n",
    "        '''\n",
    "        combin_alpha = {}\n",
    "        combin_update_dict = {}\n",
    "        combin_error = {}\n",
    "        for key, value in model_params.items():\n",
    "            if key not in self.compressor_dict:\n",
    "                combin_alpha[key] = value\n",
    "                combin_update_dict[key] = {}\n",
    "                combin_error[key] = torch.zeros_like(value)\n",
    "                continue\n",
    "            compressor = self.compressor_dict[key]\n",
    "            if can_update_basis_func is not None:\n",
    "                if can_update_basis_func(**kwargs):\n",
    "                    combin_update_dict[key] = compressor.update_basis_by_vector(value)\n",
    "                else:\n",
    "                    combin_update_dict[key] = {}\n",
    "            combin_alpha[key], combin_error[key] = compressor.compress(value)\n",
    "            # res = compressor.uncompress(combin_alpha[key], value.shape)\n",
    "            # sim = cos_similar(value, res)\n",
    "            # print(f\"key {key}, cos_similar {sim}\")\n",
    "        return combin_alpha, combin_update_dict, combin_error\n",
    "\n",
    "    def uncompress(self, combin_alpha:Dict[str, Tensor], templete_model_params:Dict[str, Tensor]) -> Dict[str, Tensor]:\n",
    "        '''\n",
    "        根据combin_alpha解压, 如果key不在compressor_dict中, 则无需解压\n",
    "        Args:\n",
    "            combin_alpha: 压缩后的alpha字典\n",
    "            templete_model_params: 参数模板，用于指定解压后的参数形状\n",
    "        Returns:\n",
    "            dict: 解压后的模型参数\n",
    "        '''\n",
    "        res = {}\n",
    "        for key, value in combin_alpha.items():\n",
    "            if key not in self.compressor_dict:\n",
    "                res[key] = value\n",
    "            else:\n",
    "                res[key] = self.compressor_dict[key].uncompress(value, templete_model_params[key].shape)\n",
    "        return res\n",
    "    \n",
    "    def update(self, combin_update_dict:Dict[str, Dict[int, Tensor]]):\n",
    "        '''\n",
    "        更新combine中全部compressor的基\n",
    "        Args:\n",
    "            combin_update_dict: key是参数名, value是更新字典, 更新字典的key是更新位置, value是更新的值\n",
    "        '''\n",
    "        for key, value in combin_update_dict.items():\n",
    "            if key not in self.compressor_dict:\n",
    "                continue\n",
    "            compressor = self.compressor_dict[key]\n",
    "            compressor.update_basis(value)\n",
    "\n",
    "class QSGDQuantizer:\n",
    "    def __init__(self, num_levels=256):\n",
    "        self.num_levels = num_levels\n",
    "\n",
    "    def quantize(self, tensor:torch.Tensor):\n",
    "        norm = tensor.norm(p=2)\n",
    "        scale = norm / self.num_levels\n",
    "        sign = tensor.sign()\n",
    "        abs_tensor = tensor.abs()\n",
    "        q = (abs_tensor / scale).floor()\n",
    "        prob = (abs_tensor / scale) - q\n",
    "        rand_tensor = torch.rand_like(prob)\n",
    "        q += torch.where(rand_tensor < prob, torch.ones_like(q), torch.zeros_like(q))\n",
    "        quantized_tensor = sign * q\n",
    "        return quantized_tensor, 0, scale\n",
    "    \n",
    "    def dequantize(self, quantized_tensor, min_val, scale):\n",
    "        dequantized_tensor = quantized_tensor * scale\n",
    "        return dequantized_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.compressor_utils import QuickSlideSVDCompressor\n",
    "# 512, 256, 3, 3\n",
    "compresser = QuickSlideSVDCompressor(100, 100, 512, 'float32')\n",
    "layername = 'base.layer3.0.conv1.weight'\n",
    "v_5 = weight_dict[0][0][layername]\n",
    "update_dict = compresser.update_basis_by_vector(v_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_D/cur_D: 76/100\n",
      "Th-1: before:   0.50335, after:   0.77459 ==> Update_dict:dict_keys([0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 82, 85])\n",
      "actual_D/cur_D: 62/100\n",
      "Th-2: before:   0.54977, after:   0.78478 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 50, 53, 57, 65, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 91, 98])\n",
      "actual_D/cur_D: 54/100\n",
      "Th-3: before:   0.59461, after:   0.77198 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 42, 43, 45, 48, 49, 51, 52, 54, 55, 56, 58, 59, 61, 62, 87, 90])\n",
      "actual_D/cur_D: 55/100\n",
      "Th-4: before:   0.61026, after:   0.74121 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 36, 37, 38, 40, 41, 44, 46, 47, 50, 53, 57, 63, 64, 65, 66, 67, 69, 70, 71, 72, 79, 80, 83, 95])\n",
      "actual_D/cur_D: 56/100\n",
      "Th-5: before:   0.60115, after:   0.72246 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 50, 57, 60, 68, 73, 75, 78, 81, 86, 91, 92, 93, 94])\n",
      "actual_D/cur_D: 55/100\n",
      "Th-6: before:   0.60726, after:   0.70907 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 43, 47, 48, 49, 51, 52, 63, 66, 74, 77, 82, 84, 85, 96, 97])\n",
      "actual_D/cur_D: 53/100\n",
      "Th-7: before:   0.60841, after:   0.70261 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 40, 43, 44, 53, 54, 55, 56, 58, 59, 61, 69, 70, 76, 88, 89, 98])\n",
      "actual_D/cur_D: 49/100\n",
      "Th-8: before:   0.61650, after:   0.69885 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 38, 39, 42, 43, 45, 46, 50, 53, 57, 60, 62, 64, 71, 72, 90])\n",
      "actual_D/cur_D: 46/100\n",
      "Th-9: before:   0.62578, after:   0.69340 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 51, 65, 67, 68, 79, 80, 83, 87])\n",
      "actual_D/cur_D: 43/100\n",
      "Th-10: before:   0.63284, after:   0.69475 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 38, 42, 47, 48, 52, 54, 58, 66, 73, 78, 93])\n",
      "actual_D/cur_D: 39/100\n",
      "Th-11: before:   0.64657, after:   0.69709 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 37, 39, 44, 45, 49, 81, 84, 92, 95])\n",
      "actual_D/cur_D: 34/100\n",
      "Th-12: before:   0.65394, after:   0.69677 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 30, 31, 32, 35, 40, 61, 74, 75, 77, 85])\n",
      "actual_D/cur_D: 32/100\n",
      "Th-13: before:   0.66050, after:   0.69732 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 33, 36, 43, 55, 56, 63, 69, 70, 82])\n",
      "actual_D/cur_D: 28/100\n",
      "Th-14: before:   0.66820, after:   0.69890 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 34, 50, 53, 59, 76, 97])\n",
      "actual_D/cur_D: 26/100\n",
      "Th-15: before:   0.67309, after:   0.69734 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 22, 25, 26, 27, 35, 41, 46, 86, 94, 96])\n",
      "actual_D/cur_D: 25/100\n",
      "Th-16: before:   0.67375, after:   0.69868 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 24, 26, 32, 33, 42, 48, 65])\n",
      "actual_D/cur_D: 24/50\n",
      "Th-17: before:   0.67750, after:   0.69838 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 17, 20, 23, 27, 30, 31, 38, 47, 62, 88])\n",
      "actual_D/cur_D: 22/50\n",
      "Th-18: before:   0.67903, after:   0.69974 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 22, 23, 25, 28, 51, 73])\n",
      "actual_D/cur_D: 21/50\n",
      "Th-19: before:   0.68042, after:   0.69848 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 16, 36, 39, 52, 67, 71, 83, 89])\n",
      "actual_D/cur_D: 22/50\n",
      "Th-20: before:   0.68270, after:   0.70080 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 29, 36, 44, 57, 60, 61, 64, 91])\n",
      "actual_D/cur_D: 20/50\n",
      "Th-21: before:   0.68470, after:   0.70301 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 16, 29, 37, 40, 43, 54, 66, 68])\n",
      "actual_D/cur_D: 18/50\n",
      "Th-22: before:   0.68837, after:   0.70362 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 39, 14, 79, 16, 80, 81, 21])\n",
      "actual_D/cur_D: 16/50\n",
      "Th-23: before:   0.68957, after:   0.70252 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 41, 12, 13, 45, 50, 19])\n",
      "actual_D/cur_D: 14/50\n",
      "Th-24: before:   0.69327, after:   0.70428 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 41, 11, 49, 18, 87])\n",
      "actual_D/cur_D: 14/50\n",
      "Th-25: before:   0.69567, after:   0.70474 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 39, 72, 14, 17, 52, 55])\n",
      "actual_D/cur_D: 14/50\n",
      "Th-26: before:   0.69441, after:   0.70404 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 58, 9, 74, 46, 15, 26, 94])\n",
      "actual_D/cur_D: 14/50\n",
      "Th-27: before:   0.69531, after:   0.70576 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 34, 70, 90, 14, 58, 31])\n",
      "actual_D/cur_D: 15/50\n",
      "Th-28: before:   0.69567, after:   0.70547 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 32, 35, 98, 10, 84, 56, 92, 30])\n",
      "actual_D/cur_D: 15/50\n",
      "Th-29: before:   0.69484, after:   0.70730 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 32, 33, 35, 39, 75, 76, 98, 22])\n",
      "actual_D/cur_D: 13/50\n",
      "Th-30: before:   0.69918, after:   0.70837 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 32, 33, 36, 71, 62])\n",
      "actual_D/cur_D: 13/50\n",
      "Th-31: before:   0.69981, after:   0.70731 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 69, 72, 78, 63])\n",
      "actual_D/cur_D: 12/50\n",
      "Th-32: before:   0.70058, after:   0.70888 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 11, 44, 20, 24, 95])\n",
      "actual_D/cur_D: 12/50\n",
      "Th-33: before:   0.70259, after:   0.70956 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 8, 79, 53, 23, 29])\n",
      "actual_D/cur_D: 12/50\n",
      "Th-34: before:   0.70333, after:   0.71077 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 59, 42, 43, 27])\n",
      "actual_D/cur_D: 11/25\n",
      "Th-35: before:   0.70307, after:   0.71074 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 35, 67, 41, 11])\n",
      "actual_D/cur_D: 10/25\n",
      "Th-36: before:   0.70419, after:   0.70987 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 32, 7, 74, 85])\n",
      "actual_D/cur_D: 10/25\n",
      "Th-37: before:   0.70568, after:   0.71126 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 10, 25, 57])\n",
      "actual_D/cur_D: 10/25\n",
      "Th-38: before:   0.70435, after:   0.70982 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 32, 34, 69, 9, 12])\n",
      "actual_D/cur_D: 10/25\n",
      "Th-39: before:   0.70321, after:   0.70942 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 32, 96, 51, 83])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-40: before:   0.70747, after:   0.71273 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 32, 38, 82])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-41: before:   0.70729, after:   0.71112 ==> Update_dict:dict_keys([0, 1, 2, 3, 47, 48, 79, 61])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-42: before:   0.70640, after:   0.71203 ==> Update_dict:dict_keys([0, 1, 2, 3, 34, 47, 48, 84])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-43: before:   0.70721, after:   0.71085 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 40, 46])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-44: before:   0.70919, after:   0.71292 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 37, 77, 86])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-45: before:   0.70573, after:   0.71088 ==> Update_dict:dict_keys([0, 1, 2, 3, 67, 8, 60, 93])\n",
      "actual_D/cur_D: 6/25\n",
      "Th-46: before:   0.71565, after:   0.71967 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 67])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-47: before:   0.70452, after:   0.70652 ==> Update_dict:dict_keys([0, 1, 37, 6, 7, 40, 13, 80])\n",
      "actual_D/cur_D: 7/25\n",
      "Th-48: before:   0.71365, after:   0.71904 ==> Update_dict:dict_keys([0, 1, 37, 6, 7, 40, 13])\n",
      "actual_D/cur_D: 8/25\n",
      "Th-49: before:   0.70619, after:   0.70826 ==> Update_dict:dict_keys([0, 5, 44, 45, 15, 80, 18, 59])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0][layername]\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        update_dict = compresser.update_basis_by_vector(v_test, update_threshold=0)\n",
    "        a_test, e_test_after = compresser.compress(v_test)\n",
    "        g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "        after = cos_similar(g_test, v_test)\n",
    "        if after < before:\n",
    "            if e_test_after.norm() > e_test.norm():\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e:{e_test.norm()} after e:{e_test_after.norm()}\")\n",
    "            else:\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e_test_after < e_test but after_similar < before_similar\")\n",
    "        else:\n",
    "            print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()}\")\n",
    "    else:\n",
    "        print(f\"Th-{i}: before:{before:10.5f} e:{e_test.norm()} after e:{e_test_after.norm()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th 0.3954788148403168\n",
      "2-th 0.38685572147369385\n",
      "3-th 0.38566067814826965\n",
      "4-th 0.4078787863254547\n",
      "5-th 0.39017173647880554\n",
      "6-th 0.38016679883003235\n",
      "7-th 0.3959686756134033\n",
      "8-th 0.398908793926239\n",
      "9-th 0.3915354311466217\n",
      "10-th 0.4029323160648346\n",
      "11-th 0.40529799461364746\n",
      "12-th 0.392452597618103\n",
      "13-th 0.3967442512512207\n",
      "14-th 0.3904167711734772\n",
      "15-th 0.3983614444732666\n",
      "16-th 0.3839189410209656\n",
      "17-th 0.39532017707824707\n",
      "18-th 0.3997047245502472\n",
      "19-th 0.3955429792404175\n",
      "20-th 0.3920809030532837\n",
      "21-th 0.38374629616737366\n",
      "22-th 0.391897976398468\n",
      "23-th 0.38946467638015747\n",
      "24-th 0.3910553753376007\n",
      "25-th 0.3862779438495636\n",
      "26-th 0.385198712348938\n",
      "27-th 0.38837939500808716\n",
      "28-th 0.3965727388858795\n",
      "29-th 0.3846668004989624\n",
      "30-th 0.38984793424606323\n",
      "31-th 0.3796626925468445\n",
      "32-th 0.38867342472076416\n",
      "33-th 0.3884607255458832\n",
      "34-th 0.3864929974079132\n",
      "35-th 0.38782989978790283\n",
      "36-th 0.39541861414909363\n",
      "37-th 0.3933473825454712\n",
      "38-th 0.38715362548828125\n",
      "39-th 0.3878777325153351\n",
      "40-th 0.3889986276626587\n",
      "41-th 0.3853163421154022\n",
      "42-th 0.3877255320549011\n",
      "43-th 0.38699012994766235\n",
      "44-th 0.38765379786491394\n",
      "45-th 0.39312493801116943\n",
      "46-th 0.38547635078430176\n",
      "47-th 0.38948893547058105\n",
      "48-th 0.38843590021133423\n",
      "49-th 0.38356828689575195\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0]['classifier.fc1.weight']\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "    print(f\"{i}-th {before}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
