{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utils import *\n",
    "tag = f\"c0\"\n",
    "filter = LayerFilter(unselect_keys=['bn', 'num_batches_tracked','downsample'], all_select_keys=['layer'])\n",
    "weight_dict = load_weight_dict_by_tag('../out/FedAMC-amc_alexnet_cosine_0.97_0.2_4_0.65/2024-08-30-15:13:54/grad_lists', tag)\n",
    "# cal_similay_by_tag('weight_lists/202405281805-avg-ss/',\"server\", unselect_keys=['bn', 'num_batches_tracked','downsample'], describe='202405281805-avg-ss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'base.conv1.weight' : torch.Size([64, 3, 5, 5]),\n",
      "'base.conv1.bias' : torch.Size([64]),\n",
      "'base.bn1.weight' : torch.Size([64]),\n",
      "'base.bn1.bias' : torch.Size([64]),\n",
      "'base.bn1.running_mean' : torch.Size([64]),\n",
      "'base.bn1.running_var' : torch.Size([64]),\n",
      "'base.bn1.num_batches_tracked' : torch.Size([]),\n",
      "'base.conv2.weight' : torch.Size([192, 64, 5, 5]),\n",
      "'base.conv2.bias' : torch.Size([192]),\n",
      "'base.bn2.weight' : torch.Size([192]),\n",
      "'base.bn2.bias' : torch.Size([192]),\n",
      "'base.bn2.running_mean' : torch.Size([192]),\n",
      "'base.bn2.running_var' : torch.Size([192]),\n",
      "'base.bn2.num_batches_tracked' : torch.Size([]),\n",
      "'base.conv3.weight' : torch.Size([384, 192, 3, 3]),\n",
      "'base.conv3.bias' : torch.Size([384]),\n",
      "'base.bn3.weight' : torch.Size([384]),\n",
      "'base.bn3.bias' : torch.Size([384]),\n",
      "'base.bn3.running_mean' : torch.Size([384]),\n",
      "'base.bn3.running_var' : torch.Size([384]),\n",
      "'base.bn3.num_batches_tracked' : torch.Size([]),\n",
      "'base.conv4.weight' : torch.Size([256, 384, 3, 3]),\n",
      "'base.conv4.bias' : torch.Size([256]),\n",
      "'base.bn4.weight' : torch.Size([256]),\n",
      "'base.bn4.bias' : torch.Size([256]),\n",
      "'base.bn4.running_mean' : torch.Size([256]),\n",
      "'base.bn4.running_var' : torch.Size([256]),\n",
      "'base.bn4.num_batches_tracked' : torch.Size([]),\n",
      "'base.conv5.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.conv5.bias' : torch.Size([256]),\n",
      "'base.bn5.weight' : torch.Size([256]),\n",
      "'base.bn5.bias' : torch.Size([256]),\n",
      "'base.bn5.running_mean' : torch.Size([256]),\n",
      "'base.bn5.running_var' : torch.Size([256]),\n",
      "'base.bn5.num_batches_tracked' : torch.Size([]),\n",
      "'classifier.fc1.weight' : torch.Size([4096, 9216]),\n",
      "'classifier.fc1.bias' : torch.Size([4096]),\n",
      "'classifier.bn6.weight' : torch.Size([4096]),\n",
      "'classifier.bn6.bias' : torch.Size([4096]),\n",
      "'classifier.bn6.running_mean' : torch.Size([4096]),\n",
      "'classifier.bn6.running_var' : torch.Size([4096]),\n",
      "'classifier.bn6.num_batches_tracked' : torch.Size([]),\n",
      "'classifier.fc2.weight' : torch.Size([4096, 4096]),\n",
      "'classifier.fc2.bias' : torch.Size([4096]),\n",
      "'classifier.bn7.weight' : torch.Size([4096]),\n",
      "'classifier.bn7.bias' : torch.Size([4096]),\n",
      "'classifier.bn7.running_mean' : torch.Size([4096]),\n",
      "'classifier.bn7.running_var' : torch.Size([4096]),\n",
      "'classifier.bn7.num_batches_tracked' : torch.Size([]),\n",
      "'classifier.fc3.weight' : torch.Size([10, 4096]),\n",
      "'classifier.fc3.bias' : torch.Size([10]),\n"
     ]
    }
   ],
   "source": [
    "for i in weight_dict[0][0].keys():\n",
    "    print(f\"'{i}' : {weight_dict[0][0][i].shape},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class SlideSVDCompress:\n",
    "    def __init__(self, K, D, L):\n",
    "        self.K = K # U的列数\n",
    "        self.D = D # 主动更新的维度\n",
    "        self.L = L # 参数切片的长度\n",
    "        self.U = None # 基础的U\n",
    "\n",
    "    def update_basis(self, update_dict:Dict[int, torch.Tensor]):\n",
    "        if self.U is None:\n",
    "            assert len(update_dict) == self.K, f\"First update_dict length must be {self.K}\"\n",
    "            self.U = torch.cat(list(update_dict.values()), dim=1)\n",
    "        \n",
    "        # key是更新位置，value是更新的值\n",
    "        for k, v in update_dict.items():\n",
    "            self.U[:,k] = v.clone().detach()\n",
    "\n",
    "    def update_basis_by_vector(self, vector, update_threshold=0):\n",
    "        '''\n",
    "        Return update_dict\n",
    "        '''\n",
    "        # 通过向量更新U\n",
    "        flatten_L = vector.numel() if len(vector.shape) == 1 else (vector.numel() // vector.shape[0])\n",
    "        if flatten_L % self.L != 0:\n",
    "            return {}\n",
    "        vector = vector.reshape(-1, self.L)\n",
    "        if self.K > vector.shape[0]:\n",
    "            raise ValueError(f\"K {self.K} must less than vector.shape[0] {vector.shape[0]}\")\n",
    "        update_dict = {}\n",
    "        vector_t = vector.T\n",
    "        if self.U is None:\n",
    "            # 通过SVD分解得到U\n",
    "            U, S, V = torch.linalg.svd(vector_t, full_matrices=False)\n",
    "            self.U = U[:,:self.K]\n",
    "            # update_dict 为全部U向量\n",
    "            for i in range(self.K):\n",
    "                update_dict[i] = self.U[:,i]\n",
    "        \n",
    "        elif self.D > 0:\n",
    "            # 通过U重构vector\n",
    "            a = self.U.T @ vector_t\n",
    "            g = self.U @ a\n",
    "            e = vector_t - g\n",
    "            U_e, S_e, V_e = torch.linalg.svd(e, full_matrices=False)\n",
    "            U_K_e = torch.cat([self.U, U_e[:,:self.D]], dim=1)\n",
    "\n",
    "            a = U_K_e.T @ vector_t\n",
    "            \n",
    "            contribution = torch.sum(a ** 2, dim=1)  # 计算每个正交向量的贡献度（平方和）\n",
    "            _, min_indices = torch.topk(contribution, k=self.D, largest=False)\n",
    "\n",
    "            min_indices_set = set(min_indices.tolist())\n",
    "            wait_D_update_set = set([i for i in range(self.K, self.K+self.D)])\n",
    "            sub_index = min_indices_set - wait_D_update_set\n",
    "            add_index = wait_D_update_set - min_indices_set\n",
    "\n",
    "            # 交换列\n",
    "            U_K_e[:,list(sub_index)] = U_K_e[:,list(add_index)]\n",
    "            U_K = U_K_e[:,:self.K]\n",
    "            a_2 = U_K.T @ vector_t\n",
    "            g_2 = U_K @ a_2\n",
    "            e_2 = vector_t - g_2\n",
    "\n",
    "            # 若更新后的误差变化小于阈值，则不更新\n",
    "            # print(f\"de {(e.norm() - e_2.norm())/e.norm()}, update_threshold {update_threshold}\")\n",
    "            if (e.norm() - e_2.norm())/e.norm() < update_threshold:\n",
    "                return {}\n",
    "            \n",
    "            self.U = U_K_e[:,:self.K]\n",
    "            # 返回更新列字典\n",
    "            for i in sub_index:\n",
    "                update_dict[i] = U_K_e[:,i].clone().detach()\n",
    "        \n",
    "        return update_dict\n",
    "\n",
    "    def compress(self, vector):\n",
    "        flatten_L = vector.numel() if len(vector.shape) == 1 else (vector.numel() // vector.shape[0])\n",
    "        if flatten_L % self.L != 0:\n",
    "            print(f\"vector.numel() // vector.shape[0] {flatten_L} can't divide L {self.L}. Return itself\")\n",
    "            return vector, 0\n",
    "        else:\n",
    "            vector = vector.reshape(-1, self.L)\n",
    "\n",
    "        vector_t = vector.T\n",
    "        # 通过U重构vector\n",
    "        a = self.U.T @ vector_t\n",
    "        g = self.U @ a\n",
    "        e = vector_t - g\n",
    "        return a, e.T.reshape(vector.shape)\n",
    "\n",
    "    def uncompress(self, a:Tensor, shape = None):\n",
    "        # 如果a的维度刚好等于shape，直接返回\n",
    "        if a.shape == shape:\n",
    "            return a\n",
    "        elif shape is None:\n",
    "            return (self.U @ a).T\n",
    "        else:\n",
    "            return (self.U @ a).T.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressorCombinModel:\n",
    "    def __init__(self, setting_dict:Dict[str, tuple]):\n",
    "        self.setting_dict = setting_dict\n",
    "        self.compressor_dict:Dict[str, SlideSVDCompress] = {}\n",
    "        for key, value in setting_dict.items():\n",
    "            self.compressor_dict[key] = SlideSVDCompress(*value)\n",
    "\n",
    "    def compress(self, model_params:Dict[str, Tensor], can_update_basis_func=None, **kwargs):\n",
    "        compress_dict = {}\n",
    "        combin_update_dict = {}\n",
    "        for key, value in model_params.items():\n",
    "            compressor = self.compressor_dict[key]\n",
    "            if can_update_basis_func is not None:\n",
    "                if can_update_basis_func(**kwargs):\n",
    "                    combin_update_dict[key] = compressor.update_basis_by_vector(value)\n",
    "                else:\n",
    "                    combin_update_dict[key] = {}\n",
    "            compress_dict[key], _ = compressor.compress(value)\n",
    "        return compress_dict, combin_update_dict\n",
    "\n",
    "    def uncompress(self, compress_model_params:Dict[str, Tensor], target_model_params:Dict[str, Tensor]):\n",
    "        for key, value in compress_model_params.items():\n",
    "            target_model_params[key] = self.compressor_dict[key].uncompress(value, target_model_params[key].shape)\n",
    "    \n",
    "    def update(self, combin_update_dict:Dict[str, Dict[int, Tensor]]):\n",
    "        for key, value in combin_update_dict.items():\n",
    "            compressor = self.compressor_dict[key]\n",
    "            compressor.update_basis(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_K_D_L(M, K=None, D=None, L=None):\n",
    "    # vector = vector.flatten()\n",
    "    # M = vector.shape[0]\n",
    "    if K is None and D is not None and L is not None:\n",
    "        max = L // 2\n",
    "        K = D * L * L // M\n",
    "        if K > max:\n",
    "            raise ValueError(f\"Not good. K is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is None and L is not None:\n",
    "        if L // K <= 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        max = M // (4 * K)\n",
    "        D = K * M // (L * L)\n",
    "        if D > max:\n",
    "            raise ValueError(f\"Not good. D is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        min = 2 * K\n",
    "        L = int(math.sqrt(M * K // D))\n",
    "        if L < min:\n",
    "            raise ValueError(f\"Not good. L is too small, min is {min}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is not None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        if L // K < 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        r = K / L + D * L / M\n",
    "    else:\n",
    "        raise ValueError(f\"K, D, L must have one None\")\n",
    "    \n",
    "    if K < D:\n",
    "        raise ValueError(f\"Not good. K < D, now is {K} < {D}\")\n",
    "    return K, D, L, 1 - r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2, D=2, L=64, r=0.9375\n"
     ]
    }
   ],
   "source": [
    "K, D, L, r = cal_K_D_L(4096,K=2, D=2, L=64)\n",
    "print(f\"K={K}, D={D}, L={L}, r={r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "4-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "6-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "8-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "10-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "12-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "14-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "16-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "18-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "20-th max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n",
      "max_K=2, max_D=1, max_L=91, max_r=0.955805181146978\n"
     ]
    }
   ],
   "source": [
    "# 遍历K和D，找到最好的K和D，使得r最大\n",
    "max_r = 0\n",
    "max_K = 0\n",
    "max_D = 0\n",
    "max_L = 0\n",
    "for K in [2,4,6,8,10,12,14,16,18,20]:\n",
    "    for D in range(1, K):\n",
    "        for L in range(2*K, 1024):\n",
    "            try:\n",
    "                K, D, L, r = cal_K_D_L(4096, K=K, D=D, L=L)\n",
    "                if L < 1024 and r > max_r:\n",
    "                    max_r = r\n",
    "                    max_K = K\n",
    "                    max_D = D\n",
    "                    max_L = L\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "    print(f\"{K}-th max_K={max_K}, max_D={max_D}, max_L={max_L}, max_r={max_r}\")\n",
    "print(f\"max_K={max_K}, max_D={max_D}, max_L={max_L}, max_r={max_r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "compresser = SlideSVDCompress(2, 2, 64)\n",
    "v_5 = weight_dict[0][0]['classifier.bn7.bias']\n",
    "update_dict = compresser.update_basis_by_vector(v_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th-1: before:   0.45079, after:   0.50904 ==> Update_dict:dict_keys([1])\n",
      "Th-2: before:   0.17858, after:   0.74591 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-3: before:   0.03031, after:   0.84314 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-4: before:   0.09780, after:   0.73217 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-5: before:   0.14634, after:   0.90785 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-6: before:   0.05894, after:   0.79023 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-7: before:   0.10013, after:   0.82852 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-8: before:   0.00043, after:   0.93388 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-9: before:   0.70187, after:   0.94095 ==> Update_dict:dict_keys([1])\n",
      "Th-10: before:   0.88185, after:   0.96219 ==> Update_dict:dict_keys([1])\n",
      "Th-11: before:   0.49033, after:   0.81116 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-12: before:   0.00123, after:   0.90453 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-13: before:   0.27537, after:   0.83382 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-14: before:   0.08805, after:   0.53857 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-15: before:   0.00400, after:   0.94162 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-16: before:   0.58983, after:   0.79689 ==> Update_dict:dict_keys([1])\n",
      "Th-17: before:   0.44077, after:   0.77639 ==> Update_dict:dict_keys([1])\n",
      "Th-18: before:   0.35253, after:   0.78425 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-19: before:       nan, after:   0.88477 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-20: before:   0.69243, after:   0.78044 ==> Update_dict:dict_keys([0])\n",
      "Th-21: before:   0.43650, after:   0.72883 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-22: before:   0.45731, after:   0.77928 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-23: before:   0.50203, after:   0.89116 ==> Update_dict:dict_keys([0])\n",
      "Th-24: before:   0.58146, after:   0.86955 ==> Update_dict:dict_keys([0])\n",
      "Th-25: before:   0.49334, after:   0.98595 ==> Update_dict:dict_keys([0])\n",
      "Th-26: before:   0.65551, after:   0.88162 ==> Update_dict:dict_keys([1])\n",
      "Th-27: before:   0.22699, after:   0.73979 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-28: before:   0.08768, after:   0.92549 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-29: before:   0.50916, after:   0.95132 ==> Update_dict:dict_keys([1])\n",
      "Th-30: before:   0.99117, after:   0.99117 ==> Update_dict:dict_keys([])\n",
      "Th-31: before:   0.47357, after:   0.77496 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-32: before:   0.03164, after:   0.90215 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-33: before:   0.39091, after:   0.85224 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-34: before:   0.32085, after:   0.87019 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-35: before:   0.08995, after:   0.77639 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-36: before:   0.15978, after:   0.86577 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-37: before:   0.33607, after:   0.82063 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-38: before:   0.53340, after:   0.92955 ==> Update_dict:dict_keys([0])\n",
      "Th-39: before:   0.15258, after:   0.76775 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-40: before:   0.14792, after:   0.85185 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-41: before:       nan, after:   0.83776 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-42: before:   0.37721, after:   0.81788 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-43: before:       nan, after:   0.76021 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-44: before:   0.49993, after:   0.80587 ==> Update_dict:dict_keys([0])\n",
      "Th-45: before:   0.28250, after:   0.94708 ==> Update_dict:dict_keys([0, 1])\n",
      "Th-46: before:   0.94617, after:   0.94617 ==> Update_dict:dict_keys([])\n",
      "Th-47: before:   0.78926, after:   0.89927 ==> Update_dict:dict_keys([0])\n",
      "Th-48: before:   0.59439, after:   0.97337 ==> Update_dict:dict_keys([0])\n",
      "Th-49: before:   0.93771, after:   0.93771 ==> Update_dict:dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0]['classifier.bn7.bias']\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        update_dict = compresser.update_basis_by_vector(v_test, update_threshold=0)\n",
    "        a_test, e_test_after = compresser.compress(v_test)\n",
    "        g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "        after = cos_similar(g_test, v_test)\n",
    "        if after < before:\n",
    "            if e_test_after.norm() > e_test.norm():\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e:{e_test.norm()} after e:{e_test_after.norm()}\")\n",
    "            else:\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e_test_after < e_test but after_similar < before_similar\")\n",
    "        else:\n",
    "            print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()}\")\n",
    "    else:\n",
    "        print(f\"Th-{i}: before:{before:10.5f} e:{e_test.norm()} after e:{e_test_after.norm()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th 0.3954788148403168\n",
      "2-th 0.38685572147369385\n",
      "3-th 0.38566067814826965\n",
      "4-th 0.4078787863254547\n",
      "5-th 0.39017173647880554\n",
      "6-th 0.38016679883003235\n",
      "7-th 0.3959686756134033\n",
      "8-th 0.398908793926239\n",
      "9-th 0.3915354311466217\n",
      "10-th 0.4029323160648346\n",
      "11-th 0.40529799461364746\n",
      "12-th 0.392452597618103\n",
      "13-th 0.3967442512512207\n",
      "14-th 0.3904167711734772\n",
      "15-th 0.3983614444732666\n",
      "16-th 0.3839189410209656\n",
      "17-th 0.39532017707824707\n",
      "18-th 0.3997047245502472\n",
      "19-th 0.3955429792404175\n",
      "20-th 0.3920809030532837\n",
      "21-th 0.38374629616737366\n",
      "22-th 0.391897976398468\n",
      "23-th 0.38946467638015747\n",
      "24-th 0.3910553753376007\n",
      "25-th 0.3862779438495636\n",
      "26-th 0.385198712348938\n",
      "27-th 0.38837939500808716\n",
      "28-th 0.3965727388858795\n",
      "29-th 0.3846668004989624\n",
      "30-th 0.38984793424606323\n",
      "31-th 0.3796626925468445\n",
      "32-th 0.38867342472076416\n",
      "33-th 0.3884607255458832\n",
      "34-th 0.3864929974079132\n",
      "35-th 0.38782989978790283\n",
      "36-th 0.39541861414909363\n",
      "37-th 0.3933473825454712\n",
      "38-th 0.38715362548828125\n",
      "39-th 0.3878777325153351\n",
      "40-th 0.3889986276626587\n",
      "41-th 0.3853163421154022\n",
      "42-th 0.3877255320549011\n",
      "43-th 0.38699012994766235\n",
      "44-th 0.38765379786491394\n",
      "45-th 0.39312493801116943\n",
      "46-th 0.38547635078430176\n",
      "47-th 0.38948893547058105\n",
      "48-th 0.38843590021133423\n",
      "49-th 0.38356828689575195\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0]['classifier.fc1.weight']\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "    print(f\"{i}-th {before}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_scope_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
