{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengsl/code/FL-bench/test_similar/test_utils.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weight = torch.load(weight_path)\n"
     ]
    }
   ],
   "source": [
    "from test_utils import *\n",
    "tag = f\"c0\"\n",
    "weight_dict = load_weight_dict_by_tag('../out/FedTest5-resnet18/2024-10-19-11:47:36/grad_lists', tag, max_round=2)\n",
    "# cal_similay_by_tag('weight_lists/202405281805-avg-ss/',\"server\", unselect_keys=['bn', 'num_batches_tracked','downsample'], describe='202405281805-avg-ss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = LayerFilter(unselect_keys=['num_batches_tracked','running_mean','running_var'], all_select_keys=['layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'base.layer1.0.conv1.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.0.bn1.weight' : torch.Size([64]),\n",
      "'base.layer1.0.bn1.bias' : torch.Size([64]),\n",
      "'base.layer1.0.conv2.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.0.bn2.weight' : torch.Size([64]),\n",
      "'base.layer1.0.bn2.bias' : torch.Size([64]),\n",
      "'base.layer1.1.conv1.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.1.bn1.weight' : torch.Size([64]),\n",
      "'base.layer1.1.bn1.bias' : torch.Size([64]),\n",
      "'base.layer1.1.conv2.weight' : torch.Size([64, 64, 3, 3]),\n",
      "'base.layer1.1.bn2.weight' : torch.Size([64]),\n",
      "'base.layer1.1.bn2.bias' : torch.Size([64]),\n",
      "'base.layer2.0.conv1.weight' : torch.Size([128, 64, 3, 3]),\n",
      "'base.layer2.0.bn1.weight' : torch.Size([128]),\n",
      "'base.layer2.0.bn1.bias' : torch.Size([128]),\n",
      "'base.layer2.0.conv2.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.0.bn2.weight' : torch.Size([128]),\n",
      "'base.layer2.0.bn2.bias' : torch.Size([128]),\n",
      "'base.layer2.0.downsample.0.weight' : torch.Size([128, 64, 1, 1]),\n",
      "'base.layer2.0.downsample.1.weight' : torch.Size([128]),\n",
      "'base.layer2.0.downsample.1.bias' : torch.Size([128]),\n",
      "'base.layer2.1.conv1.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.1.bn1.weight' : torch.Size([128]),\n",
      "'base.layer2.1.bn1.bias' : torch.Size([128]),\n",
      "'base.layer2.1.conv2.weight' : torch.Size([128, 128, 3, 3]),\n",
      "'base.layer2.1.bn2.weight' : torch.Size([128]),\n",
      "'base.layer2.1.bn2.bias' : torch.Size([128]),\n",
      "'base.layer3.0.conv1.weight' : torch.Size([256, 128, 3, 3]),\n",
      "'base.layer3.0.bn1.weight' : torch.Size([256]),\n",
      "'base.layer3.0.bn1.bias' : torch.Size([256]),\n",
      "'base.layer3.0.conv2.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.0.bn2.weight' : torch.Size([256]),\n",
      "'base.layer3.0.bn2.bias' : torch.Size([256]),\n",
      "'base.layer3.0.downsample.0.weight' : torch.Size([256, 128, 1, 1]),\n",
      "'base.layer3.0.downsample.1.weight' : torch.Size([256]),\n",
      "'base.layer3.0.downsample.1.bias' : torch.Size([256]),\n",
      "'base.layer3.1.conv1.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.1.bn1.weight' : torch.Size([256]),\n",
      "'base.layer3.1.bn1.bias' : torch.Size([256]),\n",
      "'base.layer3.1.conv2.weight' : torch.Size([256, 256, 3, 3]),\n",
      "'base.layer3.1.bn2.weight' : torch.Size([256]),\n",
      "'base.layer3.1.bn2.bias' : torch.Size([256]),\n",
      "'base.layer4.0.conv1.weight' : torch.Size([512, 256, 3, 3]),\n",
      "'base.layer4.0.bn1.weight' : torch.Size([512]),\n",
      "'base.layer4.0.bn1.bias' : torch.Size([512]),\n",
      "'base.layer4.0.conv2.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.0.bn2.weight' : torch.Size([512]),\n",
      "'base.layer4.0.bn2.bias' : torch.Size([512]),\n",
      "'base.layer4.0.downsample.0.weight' : torch.Size([512, 256, 1, 1]),\n",
      "'base.layer4.0.downsample.1.weight' : torch.Size([512]),\n",
      "'base.layer4.0.downsample.1.bias' : torch.Size([512]),\n",
      "'base.layer4.1.conv1.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.1.bn1.weight' : torch.Size([512]),\n",
      "'base.layer4.1.bn1.bias' : torch.Size([512]),\n",
      "'base.layer4.1.conv2.weight' : torch.Size([512, 512, 3, 3]),\n",
      "'base.layer4.1.bn2.weight' : torch.Size([512]),\n",
      "'base.layer4.1.bn2.bias' : torch.Size([512]),\n"
     ]
    }
   ],
   "source": [
    "for i in filter(weight_dict[0][0]).keys():\n",
    "    print(f\"'{i}' : {weight_dict[0][0][i].shape},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.layer1.0.conv1.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.0.bn1.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.bn1.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.conv2.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.0.bn2.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.0.bn2.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.conv1.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.1.bn1.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.bn1.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.conv2.weight          |  147456 bytes | 0.33% | shape: torch.Size([64, 64, 3, 3])\n",
      "base.layer1.1.bn2.weight            |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer1.1.bn2.bias              |     256 bytes | 0.00% | shape: torch.Size([64])\n",
      "base.layer2.0.conv1.weight          |  294912 bytes | 0.66% | shape: torch.Size([128, 64, 3, 3])\n",
      "base.layer2.0.bn1.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.bn1.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.conv2.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.0.bn2.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.bn2.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.downsample.0.weight   |   32768 bytes | 0.07% | shape: torch.Size([128, 64, 1, 1])\n",
      "base.layer2.0.downsample.1.weight   |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.0.downsample.1.bias     |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.conv1.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.1.bn1.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.bn1.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.conv2.weight          |  589824 bytes | 1.32% | shape: torch.Size([128, 128, 3, 3])\n",
      "base.layer2.1.bn2.weight            |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer2.1.bn2.bias              |     512 bytes | 0.00% | shape: torch.Size([128])\n",
      "base.layer3.0.conv1.weight          | 1179648 bytes | 2.64% | shape: torch.Size([256, 128, 3, 3])\n",
      "base.layer3.0.bn1.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.bn1.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.conv2.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.0.bn2.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.bn2.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.downsample.0.weight   |  131072 bytes | 0.29% | shape: torch.Size([256, 128, 1, 1])\n",
      "base.layer3.0.downsample.1.weight   |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.0.downsample.1.bias     |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.conv1.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.1.bn1.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.bn1.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.conv2.weight          | 2359296 bytes | 5.28% | shape: torch.Size([256, 256, 3, 3])\n",
      "base.layer3.1.bn2.weight            |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer3.1.bn2.bias              |    1024 bytes | 0.00% | shape: torch.Size([256])\n",
      "base.layer4.0.conv1.weight          | 4718592 bytes | 10.56% | shape: torch.Size([512, 256, 3, 3])\n",
      "base.layer4.0.bn1.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.bn1.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.conv2.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.0.bn2.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.bn2.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.downsample.0.weight   |  524288 bytes | 1.17% | shape: torch.Size([512, 256, 1, 1])\n",
      "base.layer4.0.downsample.1.weight   |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.0.downsample.1.bias     |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.conv1.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.1.bn1.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.bn1.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.conv2.weight          | 9437184 bytes | 21.13% | shape: torch.Size([512, 512, 3, 3])\n",
      "base.layer4.1.bn2.weight            |    2048 bytes | 0.00% | shape: torch.Size([512])\n",
      "base.layer4.1.bn2.bias              |    2048 bytes | 0.00% | shape: torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "def cal_sparse(weight:Tensor):\n",
    "    return 100 * (1 - torch.count_nonzero(weight) / weight.numel())\n",
    "weight_0 = filter(weight_dict[0][0])\n",
    "# total_size = calculate_data_size(weight_0)\n",
    "for i in weight_0.keys():\n",
    "    # 计算稀疏率\n",
    "    print(f\"{i:35} | {weight_0[i].shape} | {cal_sparse(weight_0[i]):.2f}%\")\n",
    "    # size = cal_memory(weight_0[i])\n",
    "    # ratio = size / total_size\n",
    "    # print(f\"{i:35} | {size:7} bytes | {ratio * 100:.2f}% | shape: {weight_0[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M 2359296, size: 98304.0, ratio: 0.9583333333333334, w1: 49152.0 0.50, w2: 0.50\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def cal_size(M, K, D, L):\n",
    "    if isinstance(M, list):\n",
    "        M = reduce(lambda x, y: x * y, M)\n",
    "    w1 = K * M / L \n",
    "    w2 = D * L\n",
    "    w = w1 + w2\n",
    "    r = 1 - w / M\n",
    "    print(f\"M {M}, size: {w}, ratio: {r}, w1: {w1} {w1/w:.2f}, w2: {w2/w:.2f}\")\n",
    "cal_size([512, 512, 3, 3], 32, 32, 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_K_D_L(M, K=None, D=None, L=None):\n",
    "    # vector = vector.flatten()\n",
    "    # M = vector.shape[0]\n",
    "    if K is None and D is not None and L is not None:\n",
    "        max = L // 2\n",
    "        K = D * L * L // M\n",
    "        if K > max:\n",
    "            raise ValueError(f\"Not good. K is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is None and L is not None:\n",
    "        if L // K <= 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        max = M // (4 * K)\n",
    "        D = K * M // (L * L)\n",
    "        if D > max:\n",
    "            raise ValueError(f\"Not good. D is too large, max is {max}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        min = 2 * K\n",
    "        L = int(math.sqrt(M * K // D))\n",
    "        if L < min:\n",
    "            raise ValueError(f\"Not good. L is too small, min is {min}\")\n",
    "        else:\n",
    "            r = 2 * L * D / M\n",
    "    elif K is not None and D is not None and L is not None:\n",
    "        if K * D * 4 >= M:\n",
    "            raise ValueError(f\"Not good. K * D * 4 is too large, max is {M // 4}, now is {K * D * 4}\")\n",
    "        if L // K < 2:\n",
    "            raise ValueError(f\"Not good. L // K is too small, min is 2, now is {L // K}\")\n",
    "        r = K / L + D * L / M\n",
    "    else:\n",
    "        raise ValueError(f\"K, D, L must have one None\")\n",
    "    \n",
    "    if K < D:\n",
    "        raise ValueError(f\"Not good. K < D, now is {K} < {D}\")\n",
    "    return K, D, L, 1 - r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=32, D=32, L=768, r=0.9479166666666666\n"
     ]
    }
   ],
   "source": [
    "K, max_D, L, r = cal_K_D_L(512*512*3*3,K=32, D=32, L=256*3)\n",
    "print(f\"K={K}, D={max_D}, L={L}, r={r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.compressor_utils import QuickSlideSVDCompressor\n",
    "# 512, 256, 3, 3\n",
    "compresser = QuickSlideSVDCompressor(64, 64, 1536, 'float32')\n",
    "layername = 'base.layer4.1.conv2.weight'\n",
    "v_5 = weight_dict[0][0][layername]\n",
    "update_dict = compresser.update_basis_by_vector(v_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_D/cur_D: 36/64\n",
      "Th-1: before:   0.48425, after:   0.78095 ==> Update_dict:dict_keys([0, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 24, 27, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 51, 52, 53, 54, 55, 58, 59])\n",
      "actual_D/cur_D: 33/64\n",
      "Th-2: before:   0.56554, after:   0.76036 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 39, 43, 45, 46])\n",
      "actual_D/cur_D: 25/48\n",
      "Th-3: before:   0.61312, after:   0.73875 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 5, 6, 14, 15, 20, 21, 22, 23, 24, 26, 34, 35, 38, 39, 40, 47, 48, 49, 56, 60])\n",
      "actual_D/cur_D: 20/36\n",
      "Th-4: before:   0.65134, after:   0.69280 ==> Update_dict:dict_keys([1, 2, 3, 4, 5, 7, 9, 12, 15, 20, 21, 22, 23, 24, 26, 34, 35, 37, 40, 47])\n",
      "actual_D/cur_D: 14/27\n",
      "Th-5: before:   0.69481, after:   0.71810 ==> Update_dict:dict_keys([0, 1, 2, 3, 4, 38, 7, 8, 9, 39, 12, 13, 44, 25])\n",
      "actual_D/cur_D: 10/20\n",
      "Th-6: before:   0.72208, after:   0.73007 ==> Update_dict:dict_keys([33, 4, 5, 6, 7, 8, 38, 10, 15, 30])\n",
      "actual_D/cur_D: 7/15\n",
      "Th-7: before:   0.72434, after:   0.73013 ==> Update_dict:dict_keys([33, 8, 14, 15, 50, 20, 31])\n",
      "actual_D/cur_D: 8/30\n",
      "Th-8: before:   0.75086, after:   0.76246 ==> Update_dict:dict_keys([33, 5, 6, 7, 8, 16, 57, 28])\n",
      "actual_D/cur_D: 9/22\n",
      "Th-9: before:   0.79192, after:   0.81122 ==> Update_dict:dict_keys([33, 5, 38, 17, 18, 19, 22, 23, 27])\n",
      "actual_D/cur_D: 9/16\n",
      "Th-10: before:   0.77565, after:   0.79085 ==> Update_dict:dict_keys([33, 5, 39, 11, 12, 48, 17, 55, 25])\n",
      "actual_D/cur_D: 7/12\n",
      "Th-11: before:   0.78155, after:   0.79912 ==> Update_dict:dict_keys([33, 5, 38, 39, 11, 44, 48])\n",
      "actual_D/cur_D: 7/24\n",
      "Th-12: before:   0.79641, after:   0.81030 ==> Update_dict:dict_keys([32, 33, 2, 38, 10, 20, 21])\n",
      "actual_D/cur_D: 8/18\n",
      "Th-13: before:   0.80704, after:   0.82533 ==> Update_dict:dict_keys([32, 33, 3, 6, 13, 18, 51, 30])\n",
      "actual_D/cur_D: 7/13\n",
      "Th-14: before:   0.81777, after:   0.83238 ==> Update_dict:dict_keys([32, 33, 34, 3, 6, 18, 51])\n",
      "actual_D/cur_D: 6/26\n",
      "Th-15: before:   0.82168, after:   0.83290 ==> Update_dict:dict_keys([32, 13, 14, 50, 18, 31])\n",
      "actual_D/cur_D: 5/13\n",
      "Th-16: before:   0.83491, after:   0.84572 ==> Update_dict:dict_keys([6, 41, 18, 26, 31])\n",
      "actual_D/cur_D: 5/9\n",
      "Th-17: before:   0.85088, after:   0.85939 ==> Update_dict:dict_keys([32, 33, 3, 6, 41])\n",
      "actual_D/cur_D: 4/18\n",
      "Th-18: before:   0.85764, after:   0.86470 ==> Update_dict:dict_keys([32, 33, 3, 0])\n",
      "actual_D/cur_D: 4/9\n",
      "Th-19: before:   0.86550, after:   0.87400 ==> Update_dict:dict_keys([33, 34, 58, 6])\n",
      "actual_D/cur_D: 3/6\n",
      "Th-20: before:   0.86287, after:   0.87378 ==> Update_dict:dict_keys([38, 58, 6])\n",
      "actual_D/cur_D: 1/3\n",
      "Th-21: before:   0.87591, after:   0.87816 ==> Update_dict:dict_keys([58])\n",
      "actual_D/cur_D: 2/6\n",
      "Th-22: before:   0.87968, after:   0.88439 ==> Update_dict:dict_keys([21, 7])\n",
      "actual_D/cur_D: 1/3\n",
      "Th-23: before:   0.88372, after:   0.88625 ==> Update_dict:dict_keys([21])\n",
      "actual_D/cur_D: 3/6\n",
      "Th-24: before:   0.88227, after:   0.88486 ==> Update_dict:dict_keys([32, 1, 42])\n",
      "actual_D/cur_D: 3/12\n",
      "Th-25: before:   0.88788, after:   0.89492 ==> Update_dict:dict_keys([32, 42, 20])\n",
      "actual_D/cur_D: 3/6\n",
      "Th-26: before:   0.88514, after:   0.89045 ==> Update_dict:dict_keys([35, 4, 29])\n",
      "actual_D/cur_D: 3/12\n",
      "Th-27: before:   0.88682, after:   0.89571 ==> Update_dict:dict_keys([35, 4, 29])\n",
      "actual_D/cur_D: 2/6\n",
      "Th-28: before:   0.89601, after:   0.90025 ==> Update_dict:dict_keys([35, 4])\n",
      "actual_D/cur_D: 1/3\n",
      "Th-29: before:   0.90259, after:   0.90362 ==> Update_dict:dict_keys([35])\n",
      "actual_D/cur_D: 2/6\n",
      "Th-30: before:   0.90248, after:   0.90306 ==> Update_dict:dict_keys([24, 59])\n",
      "actual_D/cur_D: 4/12\n",
      "Th-31: before:   0.89193, after:   0.90413 ==> Update_dict:dict_keys([24, 42, 59, 21])\n",
      "actual_D/cur_D: 3/6\n",
      "Th-32: before:   0.89939, after:   0.91055 ==> Update_dict:dict_keys([24, 59, 21])\n",
      "actual_D/cur_D: 1/3\n",
      "Th-33: before:   0.90894, after:   0.90916 ==> Update_dict:dict_keys([24])\n",
      "actual_D/cur_D: 2/6\n",
      "Th-34: before:   0.90876, after:   0.91059 ==> Update_dict:dict_keys([17, 52])\n",
      "actual_D/cur_D: 1/3\n",
      "Th-35: before:   0.90712, after:   0.90960 ==> Update_dict:dict_keys([24])\n",
      "actual_D/cur_D: 2/6\n",
      "Th-36: before:   0.90729, after:   0.90921 ==> Update_dict:dict_keys([2, 22])\n",
      "actual_D/cur_D: 2/4\n",
      "Th-37: before:   0.90528, after:   0.91301 ==> Update_dict:dict_keys([2, 22])\n",
      "actual_D/cur_D: 1/2\n",
      "Th-38: before:   0.91520, after:   0.91574 ==> Update_dict:dict_keys([12])\n",
      "actual_D/cur_D: 1/4\n",
      "Th-39: before:   0.91612, after:   0.91720 ==> Update_dict:dict_keys([9])\n",
      "actual_D/cur_D: 1/2\n",
      "Th-40: before:   0.91539, after:   0.91761 ==> Update_dict:dict_keys([55])\n",
      "actual_D/cur_D: 1/4\n",
      "Th-41: before:   0.91794, after:   0.91909 ==> Update_dict:dict_keys([19])\n",
      "actual_D/cur_D: 1/2\n",
      "Th-42: before:   0.91837, after:   0.91917 ==> Update_dict:dict_keys([36])\n",
      "actual_D/cur_D: 1/4\n",
      "Th-43: before:   0.92063, after:   0.92134 ==> Update_dict:dict_keys([12])\n",
      "actual_D/cur_D: 1/2\n",
      "Th-44: before:   0.92122, after:   0.92239 ==> Update_dict:dict_keys([48])\n",
      "actual_D/cur_D: 2/4\n",
      "Th-45: before:   0.90957, after:   0.91605 ==> Update_dict:dict_keys([36, 5])\n",
      "actual_D/cur_D: 2/8\n",
      "Th-46: before:   0.91842, after:   0.92471 ==> Update_dict:dict_keys([36, 5])\n",
      "actual_D/cur_D: 1/4\n",
      "Th-47: before:   0.92420, after:   0.92483 ==> Update_dict:dict_keys([27])\n",
      "actual_D/cur_D: 2/8\n",
      "Th-48: before:   0.92461, after:   0.92552 ==> Update_dict:dict_keys([50, 13])\n",
      "actual_D/cur_D: 1/4\n",
      "Th-49: before:   0.92576, after:   0.92869 ==> Update_dict:dict_keys([62])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0][layername]\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        update_dict = compresser.update_basis_by_vector(v_test, update_threshold=0)\n",
    "        a_test, e_test_after = compresser.compress(v_test)\n",
    "        g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "        after = cos_similar(g_test, v_test)\n",
    "        if after < before:\n",
    "            if e_test_after.norm() > e_test.norm():\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e:{e_test.norm()} after e:{e_test_after.norm()}\")\n",
    "            else:\n",
    "                print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()} e_test_after < e_test but after_similar < before_similar\")\n",
    "        else:\n",
    "            print(f\"Th-{i}: before:{before:10.5f}, after:{after:10.5f} ==> Update_dict:{update_dict.keys()}\")\n",
    "    else:\n",
    "        print(f\"Th-{i}: before:{before:10.5f} e:{e_test.norm()} after e:{e_test_after.norm()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th 0.3954788148403168\n",
      "2-th 0.38685572147369385\n",
      "3-th 0.38566067814826965\n",
      "4-th 0.4078787863254547\n",
      "5-th 0.39017173647880554\n",
      "6-th 0.38016679883003235\n",
      "7-th 0.3959686756134033\n",
      "8-th 0.398908793926239\n",
      "9-th 0.3915354311466217\n",
      "10-th 0.4029323160648346\n",
      "11-th 0.40529799461364746\n",
      "12-th 0.392452597618103\n",
      "13-th 0.3967442512512207\n",
      "14-th 0.3904167711734772\n",
      "15-th 0.3983614444732666\n",
      "16-th 0.3839189410209656\n",
      "17-th 0.39532017707824707\n",
      "18-th 0.3997047245502472\n",
      "19-th 0.3955429792404175\n",
      "20-th 0.3920809030532837\n",
      "21-th 0.38374629616737366\n",
      "22-th 0.391897976398468\n",
      "23-th 0.38946467638015747\n",
      "24-th 0.3910553753376007\n",
      "25-th 0.3862779438495636\n",
      "26-th 0.385198712348938\n",
      "27-th 0.38837939500808716\n",
      "28-th 0.3965727388858795\n",
      "29-th 0.3846668004989624\n",
      "30-th 0.38984793424606323\n",
      "31-th 0.3796626925468445\n",
      "32-th 0.38867342472076416\n",
      "33-th 0.3884607255458832\n",
      "34-th 0.3864929974079132\n",
      "35-th 0.38782989978790283\n",
      "36-th 0.39541861414909363\n",
      "37-th 0.3933473825454712\n",
      "38-th 0.38715362548828125\n",
      "39-th 0.3878777325153351\n",
      "40-th 0.3889986276626587\n",
      "41-th 0.3853163421154022\n",
      "42-th 0.3877255320549011\n",
      "43-th 0.38699012994766235\n",
      "44-th 0.38765379786491394\n",
      "45-th 0.39312493801116943\n",
      "46-th 0.38547635078430176\n",
      "47-th 0.38948893547058105\n",
      "48-th 0.38843590021133423\n",
      "49-th 0.38356828689575195\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 50):\n",
    "    v_test = weight_dict[i][0]['classifier.fc1.weight']\n",
    "    a_test, e_test = compresser.compress(v_test)\n",
    "    g_test = compresser.uncompress(a_test, v_test.shape)\n",
    "    before = cos_similar(g_test, v_test)\n",
    "    print(f\"{i}-th {before}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
