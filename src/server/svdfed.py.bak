from collections import OrderedDict
from copy import deepcopy
from typing import Any, Dict

import torch
from src.client.svdfed import SVDFedClient
from src.server.fedavg import FedAvgServer
from src.utils.tools import NestedNamespace
from src.utils.my_utils import cal_memory

# Debug 记录
# 问题： testset-beforeLocalTraining 精度永远不变，loss一直NaN
# 尝试：
# 1. 改为直接本地训练，发现精度和loss都正常
# 2. 打印发现，每次训练后的梯度和参数正常，没有NaN，不同轮次的梯度和参数值也会发生变化
# 3. 去除alpha修正，问题依然存在
# 4. 检查代码逻辑，未发现问题
# 5. 去除阈值判断，隔次更新basis，使用旧basis时，问题依然存在，但每次更新basis后，精度和loss都会发生变化。
# 初步认为是basis不足以描述梯度，导致梯度更新后的参数不符合预期
# 6. 尝试输出梯度和拟合梯度的cosine相似度，发现cosine相似度很低，说明basis不足以描述梯度

class SVDFedServer(FedAvgServer):
    def __init__(
        self,
        args: NestedNamespace,
        algo: str = "SVDFed",
        unique_model=True,
        use_fedavg_client_cls=False,
        return_diff=True,
    ):
        super().__init__(args, algo, unique_model, use_fedavg_client_cls, return_diff)
        self.init_trainer(SVDFedClient, output_dir=self.output_dir)

        # self.clients_layer_basis:Dict[int, Dict[str, torch.Tensor]] = {key:{} for key in range(self.client_num)}

        self.bak_log = self.logger.log
        self.logger.log = self.log
        
        self.basis = []
        self.error:Dict[str, torch.Tensor] = {}
        self.total_error:Dict[str, torch.Tensor] = {}
        self.Z_thr = {}
        self.avg_alpha = {}
        self.layer_basis = {}
        self.layer_basis_with_state = {}

        self.Kp, self.Ki, self.Kd = 1, 1, 1
        self.gamma = 18
        self.R = 0.2
        self.L = 3
        

    def log(self, *args, **kwargs):
        # 加上时间戳 [年-月-日 时:分:秒]
        self.bak_log(f"Round {self.current_epoch}", *args, **kwargs)

    def train_one_round(self):
        """The function of indicating specific things FL method need to do (at server side) in each communication round."""
        self.log("Server Training...")
        selected_clients = sorted(self.selected_clients)
        
        
        for name in self.layer_basis_with_state.keys():
            if self.layer_basis_with_state[name][0] == 'new':
                recv_byte = cal_memory(self.layer_basis_with_state[name][1])
                for client_id in selected_clients:
                    self.clients_comm_recv_bytes[client_id] += (recv_byte)    
            recv_byte = cal_memory(self.avg_alpha[name])
            for client_id in selected_clients:
                self.clients_comm_recv_bytes[client_id] += (recv_byte)

        clients_package = self.trainer.train()
        
        for client_id in selected_clients:
            self.clients_personal_model_params[client_id] = clients_package[client_id]["personal_model_params"]
            # self.clients_layer_basis[client_id] = clients_package[client_id]["layer_basis"]
            for name, value in clients_package[client_id]['model_params_diff'].items():
                byte = cal_memory(value[1])
                if not value[0]:
                    byte += cal_memory(value[2])
                self.clients_comm_send_bytes[client_id] += byte  

        self.aggregate(clients_package)

    def package(self, client_id: int):
        """Package parameters that the client-side training needs.
        If you are implementing your own FL method and your method has different parameters to FedAvg's
        that passes from server-side to client-side, this method need to be overrided.
        All this method should do is returning a dict that contains all parameters.

        Args:
            client_id: The client ID.

        Returns:
            A dict of parameters: {
                `client_id`: The client ID.
                `local_epoch`: The num of epoches that client local training performs.
                `client_model_params`: The client model parameter dict.
                `optimizer_state`: The client model optimizer's state dict.
                `lr_scheduler_state`: The client learning scheduler's state dict.
                `return_diff`: Flag that indicates whether client should send parameters difference.
                    `False`: Client sends vanilla model parameters;
                    `True`: Client sends `diff = global - local`.
            }.
        """
        # self.log(f"Server Packaging {client_id}")
        return dict(
            client_id=client_id,
            return_diff=True,
            local_epoch=self.clients_local_epoch[client_id],
            personal_model_params = self.clients_personal_model_params[client_id],
            optimizer_state=self.clients_optimizer_state[client_id],
            lr_scheduler_state=self.clients_lr_scheduler_state[client_id],
            layer_basis_with_state=self.layer_basis_with_state,
            avg_alpha=self.avg_alpha,
            # layer_basis=self.clients_layer_basis[client_id],
        )
    
    # def get_svd_error(self, grads, U):
    #     # 依次计算grads中每个梯度的误差
    #     total_error = 0
    #     for i in range(grads.shape[1]):
    #         g = grads[:,i].squeeze()
    #         alpha = U.T @ g
    #         # tmp = U @ alpha
    #         # alpha = min(g.norm() / tmp.norm(), self.L) * alpha
    #         g_approx = U @ alpha
    #         error = g - g_approx
    #         total_error += error.norm()/g.norm()
    #     return total_error/grads.shape[1]
        

    @torch.no_grad()
    def aggregate(self, clients_package: OrderedDict[int, dict[str, Any]]):
        """Aggregate clients model parameters and produce global model parameters.

        Args:
            clients_package: Dict of client parameter packages, with format:
            {
                `client_id`: {
                    `regular_model_params`: ...,
                    `optimizer_state`: ...,
                }
            }

            About the content of client parameter package, check `FedAvgClient.package()`.
        """
        self.log("Server Aggregating...")
        for name in clients_package[0]["model_params_diff"].keys():
            alpha_list = []
            state, param, error = [], [], []
            for package in clients_package.values():
                state.append(package["model_params_diff"][name][0])
                param.append(package["model_params_diff"][name][1])
                error.append(package["model_params_diff"][name][2])
            # 全部state均为相同值
            assert all([s == state[0] for s in state]), f"State of {name} is not the same"
            # 上传真实梯度，获取basis
            if state[0]:
                grads = torch.stack(
                    param,
                    dim=-1,
                )
                # 对梯度进行SVD分解
                U, S, V = torch.svd(grads)
                # 二分找到误差低于R的最小k
                k = len(S)
                # k = 0
                # l = 0
                # r = len(S)
                # while l < r:
                #     mid = (l + r) // 2
                #     t = self.get_svd_error(grads, U[:,:mid])
                #     if t < self.R:
                #         r = mid
                #     else:
                #         l = mid + 1
                # k = l
                # self.log(f"Layer {name} basis selected maximun: {k}, error: {t}")
                # self.log(f"Layer {name} basis selected maximun: {k}, error: {t}")
                # 获取alanpha list
                # _U = U
                _U = U[:,:k]
                # 保存basis
                self.layer_basis[name] = _U
                for i in range(grads.shape[1]):
                    g = grads[:,i].squeeze()
                    alpha = _U.T @ g
                    # tmp = _U @ alpha
                    # alpha = min(g.norm() / tmp.norm(), self.L) * alpha
                    alpha_list.append(alpha)
                    self.log(f"Layer {name} {i}-th norm g_approx: {(_U @ alpha).norm()} g: {g.norm()}")
                self.layer_basis_with_state[name] = ('new', _U)
                # 删除error的key
                self.error.pop(name, None)
                self.total_error.pop(name, None)
                self.Z_thr.pop(name, None)
            else:
                
                alpha_list = param
                # tensor_error = torch.tensor(error)

                if self.current_epoch % 5 == 0:
                    self.log(f"Need update basis of {name}")
                    self.layer_basis_with_state[name] = ('update', self.layer_basis[name])                    
                else:
                    self.layer_basis_with_state[name] = ('old', self.layer_basis[name])

                # if name not in self.error:
                #     self.error[name] = tensor_error
                #     self.total_error[name] = tensor_error
                #     self.layer_basis_with_state[name] = ('old', self.layer_basis[name])
                # else:
                #     delta_error = tensor_error - self.error[name]
                #     self.error[name] = tensor_error
                #     self.total_error[name] += tensor_error
                #     z = self.Kp * tensor_error.norm() + self.Ki * self.total_error[name].norm() + self.Kd * delta_error.norm()
                #     self.log(f"Layer {name} z: {z}, z_thr: {self.Z_thr.get(name, None)}")
                #     if name not in self.Z_thr:
                #         self.Z_thr[name] = z * self.gamma
                #     elif z > self.Z_thr[name]:
                #         self.log(f"Need update basis of {name}")
                #         self.layer_basis_with_state[name] = ('update', self.layer_basis[name])
                #     else:
                #         self.layer_basis_with_state[name] = ('old', self.layer_basis[name])
                    
                # 为了测试，暂时不加入阈值，每次都更新
                # self.layer_basis_with_state[name] = ('update', self.layer_basis[name])

            self.avg_alpha[name] = torch.mean(torch.stack(alpha_list), dim=0)
