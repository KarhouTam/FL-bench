from collections import OrderedDict
from copy import deepcopy
from typing import Any

import torch
from src.server.fedavg import FedAvgServer
from src.client.signsgd import SignSGDClient
from src.utils.tools import NestedNamespace
from src.utils.my_utils import calculate_data_size
from torch.utils.data import DataLoader, Subset


class SignSGDServer(FedAvgServer):
    def __init__(
        self,
        args: NestedNamespace,
        algo: str = "SignSGD",
        unique_model=True,
        use_fedavg_client_cls=False,
        return_diff=True,
    ):
        self.use_bn = False
        super().__init__(args, algo, unique_model, use_fedavg_client_cls, return_diff)
        # init None for all clients
        self.clients_trainloader_generator = {client_id: None for client_id in range(self.client_num)}
        self.clients_eval_results = {client_id: None for client_id in range(self.client_num)}
        self.init_trainer(SignSGDClient, output_dir=self.output_dir)
    
        self.avg_sign_params = []



    def init_trainer(self, fl_client_cls=..., **extras):
        _ = super().init_trainer(fl_client_cls, **extras)
        trainset:Subset = self.trainer.worker.trainset
        trainloader:DataLoader = self.trainer.worker.trainloader
        for client_id in range(self.client_num):
            trainset.indices = self.data_indices[client_id]["train"]
            self.clients_trainloader_generator[client_id] = iter(trainloader)
        return _

    def train_one_round(self):
        """The function of indicating specific things FL method need to do (at server side) in each communication round."""
        selected_clients = sorted(self.selected_clients)

        public_model_byte = calculate_data_size(self.public_model_params, set_sparse='all',set_layout='bit')
        for client_id in selected_clients:
            self.clients_comm_recv_bytes[client_id] += public_model_byte

        clients_package = self.trainer.train()
        for client_id in selected_clients:
            tmp = {index: value for index, value in enumerate(clients_package[client_id]['model_params_diff'])}
            byte = calculate_data_size(tmp, 
                                       set_sparse='all', 
                                       set_layout='bit')
            self.clients_comm_send_bytes[client_id] += byte

        for client_id in selected_clients:
            self.clients_trainloader_generator[client_id] = clients_package[client_id]["trainloader_generator"]
            self.clients_eval_results[client_id] = clients_package[client_id]["eval_results"]
        self.aggregate(clients_package)

    @torch.no_grad()
    def aggregate(self, clients_package: OrderedDict[int, dict[str, Any]]):
        weights = 1 / len(clients_package)
        cnt = len(clients_package[0]["model_params_diff"])

        for i in range(cnt):
            diffs = torch.stack(
                [
                    package["model_params_diff"][i]
                    for package in clients_package.values()
                ],
                dim=-1,
            )
            assert torch.all((diffs == 1) | (diffs == -1) | (diffs == 0)), f"diffs has value not in [-1, 0, 1]"
            aggregated = torch.sum(
                diffs * weights, dim=-1
            )        # 只取符号，正数为1，负数为-1
            aggregated = torch.sign(aggregated)
            self.avg_sign_params.append(aggregated)


        # for name, global_param in self.avg_sign_params.items():
        #     diffs = torch.stack(
        #         [
        #             package["model_params_diff"][name]
        #             for package in clients_package.values()
        #         ],
        #         dim=-1,
        #     )
        #     # assart diffs里面只有1，-1和0
        #     assert torch.all((diffs == 1) | (diffs == -1) | (diffs == 0)), f"diffs has value not in [-1, 0, 1]"
        #     aggregated = torch.sum(
        #         diffs * weights, dim=-1, dtype=global_param.dtype
        #     ).to(global_param.device)        # 只取符号，正数为1，负数为-1
        #     aggregated = torch.sign(aggregated)
        #     self.avg_sign_params[name].data = aggregated


    def package(self, client_id: int):
        """Package parameters that the client-side training needs.
        If you are implementing your own FL method and your method has different parameters to FedAvg's
        that passes from server-side to client-side, this method need to be overrided.
        All this method should do is returning a dict that contains all parameters.

        Args:
            client_id: The client ID.

        Returns:
            A dict of parameters: {
                `client_id`: The client ID.
                `local_epoch`: The num of epoches that client local training performs.
                `client_model_params`: The client model parameter dict.
                `optimizer_state`: The client model optimizer's state dict.
                `lr_scheduler_state`: The client learning scheduler's state dict.
                `return_diff`: Flag that indicates whether client should send parameters difference.
                    `False`: Client sends vanilla model parameters;
                    `True`: Client sends `diff = global - local`.
            }.
        """
        return dict(
            client_id=client_id,
            local_epoch=self.clients_local_epoch[client_id],
            personal_model_params=self.clients_personal_model_params[client_id],
            avg_sign_params = self.avg_sign_params,
            optimizer_state=self.clients_optimizer_state[client_id],
            lr_scheduler_state=self.clients_lr_scheduler_state[client_id],
            return_diff=self.return_diff,
            trainloader_generator=self.clients_trainloader_generator[client_id],
            eval_results=self.clients_eval_results[client_id],
        )
