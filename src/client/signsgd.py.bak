from collections import OrderedDict
from copy import deepcopy
from typing import Any
import torch
from torch.optim import Optimizer

from src.client.fedavg import FedAvgClient
from src.utils.tools import (
    trainable_params,
)
from src.utils.metrics import Metrics

class SGD_distribute(Optimizer):

    def __init__(self, params):

        lr = 0.03
        momentum = 0
        weight_decay = 0
        defaults = dict(lr=lr, momentum=momentum,
                        weight_decay=weight_decay)

        super(SGD_distribute, self).__init__(params, defaults)

    def __setstate__(self, state):
        super(SGD_distribute, self).__setstate__(state)

    def step(self, avg_grad, closure=None):
        loss = None
        if closure is not None:
            loss = closure()
        for group in self.param_groups:
            for p, grad in zip(group['params'], avg_grad):
                p.data.add_(grad, alpha=-group['lr'])
        return loss
    
    def sign_grad(self):
        grad = []
        for group in self.param_groups:
            for p in group['params']:
                grad.append(torch.sign(p.grad))
        return grad


class SignSGDClient(FedAvgClient):
    def __init__(self, **commons):
        # 多出一个output_dir参数，将output_dir参数从commons中删除
        self.output_dir = commons['output_dir']
        del commons['output_dir']
        super().__init__(**commons)
        self.sign_grad=[]
        self.lr = 0.01
        self.model = self.model.to(self.device)
        self.optimizer = SGD_distribute(params=trainable_params(self.model))        

    def train_with_eval(self):
        """Wraps `fit()` with `evaluate()` and collect model evaluation results

        A model evaluation results dict: {
                `before`: {...}
                `after`: {...}
                `message`: "..."
            }
            `before` means pre-local-training.
            `after` means post-local-training
        """
        self.eval_results = {
            "before": {"train": Metrics(), "val": Metrics(), "test": Metrics()},
            "after": {"train": Metrics(), "val": Metrics(), "test": Metrics()},
        }
        self.eval_results["before"] = self.evaluate()
        # if self.local_epoch > 0:
        self.dataset.train()
        self.model.train()
        try:
            x, y = next(self.trainloader_generator)
            if len(x) <= 1:
                x, y = next(self.trainloader_generator)
        except StopIteration:
            self.trainloader_generator = iter(self.trainloader)
            x, y = next(self.trainloader_generator)
        # print(f"x: {x.shape}, y: {y.shape}")
        
        x, y = x.to(self.device), y.to(self.device)
        logit = self.model(x)
        loss = self.criterion(logit, y)
        self.optimizer.zero_grad()
        loss.backward()
        self.sign_grad = self.optimizer.sign_grad()


    @torch.no_grad()
    def set_parameters(self, package: dict[str, Any]):
        self.client_id = package["client_id"]
        self.local_epoch = package["local_epoch"]
        self.load_data_indices()

        if package["optimizer_state"]:
            self.optimizer.load_state_dict(package["optimizer_state"])
        else:
            self.optimizer.load_state_dict(self.init_optimizer_state)

        if self.lr_scheduler is not None:
            if package["lr_scheduler_state"]:
                self.lr_scheduler.load_state_dict(package["lr_scheduler_state"])
            else:
                self.lr_scheduler.load_state_dict(self.init_lr_scheduler_state)

        self.model.load_state_dict(package["personal_model_params"], strict=False)
        if self.args.common.buffers == "drop":
            self.model.load_state_dict(self.init_buffers, strict=False)

        self.trainloader_generator = package["trainloader_generator"]
        self.eval_results = package["eval_results"]

        avg_sign = package["avg_sign_params"]
        self.optimizer.step(avg_sign)
        
        if self.eval_results is not None:
            self.eval_results["after"] = self.evaluate()

            eval_msg = []
            for split, color, flag, subset in [
                ["train", "yellow", self.args.common.eval_train, self.trainset],
                ["val", "green", self.args.common.eval_val, self.valset],
                ["test", "cyan", self.args.common.eval_test, self.testset],
            ]:
                if len(subset) > 0 and flag:
                    eval_msg.append(
                        "client [{}] [{}]({})  loss: {:.4f} -> {:.4f}   accuracy: {:.2f}% -> {:.2f}%".format(
                            self.client_id,
                            color,
                            split,
                            self.eval_results["before"][split].loss,
                            self.eval_results["after"][split].loss,
                            self.eval_results["before"][split].accuracy,
                            self.eval_results["after"][split].accuracy,
                        )
                    )
            self.eval_results["message"] = eval_msg
            self.eval_results = self.eval_results
        

    def package(self):
        """Package data that client needs to transmit to the server.
        You can override this function and add more parameters.

        Returns:
            A dict: {
                `weight`: Client weight. Defaults to the size of client training set.
                `regular_model_params`: Client model parameters that will join parameter aggregation.
                `model_params_diff`: The parameter difference between the client trained and the global. `diff = global - trained`.
                `eval_results`: Client model evaluation results.
                `personal_model_params`: Client model parameters that absent to parameter aggregation.
                `optimzier_state`: Client optimizer's state dict.
                `lr_scheduler_state`: Client learning rate scheduler's state dict.
            }
        """
        model_params = self.model.state_dict()
        client_package = dict(
            weight=len(self.trainset),
            eval_results=self.eval_results,
            personal_model_params=deepcopy(model_params),
            optimizer_state=deepcopy(self.optimizer.state_dict()),
            lr_scheduler_state=(
                {}
                if self.lr_scheduler is None
                else deepcopy(self.lr_scheduler.state_dict())
            ),
            model_params_diff = self.sign_grad,
            trainloader_generator = self.trainloader_generator
        )
        return client_package

